Computer networks consist of several assets such as hardware , software , and data sources .
1.00: (Computer networks; consist; of several assets such as hardware)
1.00: (Computer networks; consist; of several assets such as software)
1.00: (Computer networks; consist; of several assets such as data sources)

several assets such as hardware , software , and data sources have often some vulnerabilities which can be exploited by attackers that violate security policies in Computer networks .
1.00: (several assets such as hardware; have; often some vulnerabilities which can be exploited by attackers)
0.96: (some vulnerabilities; can be exploited; by attackers often)
1.00: (attackers; violate; security policies in Computer networks)
1.00: (several assets such as software; have; often some vulnerabilities which can be exploited by attackers)
1.00: (several assets such as data sources; have; often some vulnerabilities which can be exploited by attackers)

Considering the limited budget , the network administrator should analyze and prioritize some vulnerabilities which can be exploited by attackers that violate security policies in the network to be able to efficiently protect a network by mitigating the most risky ones .
1.00: (the network administrator; should analyze; some vulnerabilities which can be exploited by attackers)
0.99: (some vulnerabilities; can be exploited; by attackers)
0.71: (attackers; violate; security policies in the network network)
0.16: (attackers in the network; security policies to be; able to efficiently protect a network by mitigating the most risky ones)
0.83: (attackers; to efficiently protect; a network)
1.00: (the network administrator; should prioritize; some vulnerabilities which can be exploited by attackers)
0.95: (attackers; violate; security policies in the network)
0.80: (attackers; security policies to be; able to efficiently protect a network by mitigating the most risky ones)
0.58: (attackers network; to efficiently protect; a network)

So far , several security parameters are offered to analyze security risks from the network security administrator 's perspective .
0.95: (several security parameters; are offered; to analyze security risks from the network security administrator 's perspective So far)
1.00: (several security parameters; to analyze; security risks)

The major drawback of these methods is that these methods do not consider attacker 's motivation .
0.01: (The major drawback of these methods; is; that these methods do not consider attacker 's motivation)
1.00: (these methods; do not consider; attacker 's motivation)

Depending on the motivation of potential attackers , different attack path may be selected for network security compromise .
1.00: (different attack path; may be selected; for network security compromise)

So , attacker 's motivation is a key factor in predicting the attacker 's behavior .
1.00: (attacker 's motivation; is; a key factor in predicting the attacker 's behavior)

In this paper , the attacker 's motivation is considered in the process of security risk analysis , so network administrators are able to analyze security risks more accurately .
0.43: (the attacker 's motivation network administrators; is more; in the process of security risk analysis able to analyze security risks accurately)
0.35: (so network administrators; are to analyze accurately; able security risks more)
0.44: (the attacker 's motivation; is considered; In this paper in the process of security risk analysis)

The proposed method is applied on a network and the results are compared with novel works in this area .
1.00: (The proposed method; is applied; on a network)
1.00: (the results; are compared; with novel works in this area)

The experimental results show that network administrator will be able to precisely predict the behavior of attackers and apply countermeasures more efficiently .
1.00: (network administrator; to precisely predict; the behavior of attackers)
1.00: (The experimental results; show; that network administrator will be able to precisely predict the behavior of attackers)
1.00: (network administrator; will be; able to precisely predict the behavior of attackers)
0.99: (network administrator; to apply more efficiently; countermeasures)
1.00: (The experimental results; show; that network administrator will be able to apply countermeasures more efficiently)
1.00: (network administrator; will be; able to apply countermeasures more efficiently)

Background and objective : According to the World Health Organization ( WHO ) epilepsy affects approximately 45-50 million people .
1.00: (epilepsy; affects; approximately 45-50 million people)
0.98: (epilepsy; affects; approximately 45-50 million people World)

Electroencephalogram ( EEG ) records the neurological activity in the brain and Electroencephalogram ( EEG ) is used to identify epilepsy .
1.00: (Electroencephalogram; records; the neurological activity in the brain)
1.00: (Electroencephalogram; is used; to identify epilepsy)
1.00: (Electroencephalogram; to identify; epilepsy)

Visual inspection of EEG signals is a time-consuming process and Visual inspection of EEG signals may lead to human error .
1.00: (Visual inspection of EEG signals; is; a time-consuming process)
1.00: (Visual inspection of EEG signals; may lead; to human error)

Feature extraction and classification are two main steps that are required to build an automated epilepsy detection framework .
1.00: (Feature extraction; are; two main steps that are required to build an automated epilepsy detection framework)
1.00: (two main steps; are required; to build an automated epilepsy detection framework)
1.00: (two main steps; to build; an automated epilepsy detection framework)
0.01: (classification; are; two main steps that are required to build an automated epilepsy detection framework)

Feature extraction reduces the dimensions of the input signal by retaining informative features and the classifier assigns a proper class label to the extracted feature vector .
1.00: (Feature extraction; reduces; the dimensions of the input signal by retaining informative features)
1.00: (the classifier; assigns; a proper class label to the extracted feature vector)

Our aim is to present effective feature extraction techniques for automated epileptic EEG signal classification .
1.00: (Our aim; is; to present effective feature extraction techniques for automated epileptic EEG signal classification)

Methods : In this study , two effective feature extraction techniques ( Local .

Neighbor Descriptive Pattern [ LNDP ] and One-dimensional Local Gradient Pattern [ 1D-LGP ] ) have been introduced to classify epileptic EEG signals .
1.00: (Neighbor Descriptive Pattern; have been introduced; to classify epileptic EEG signals)
0.97: (Neighbor Descriptive Pattern; to classify; epileptic EEG signals)
1.00: (One-dimensional Local Gradient Pattern; have been introduced; to classify epileptic EEG signals)
0.89: (One-dimensional Local Gradient Pattern; to classify; epileptic EEG signals)

The classification between epileptic seizure and non -seizure signals is performed using different machine learning classifiers .
0.92: (The classification between epileptic seizure and non -seizure signals; is performed; using different machine learning)

The benchmark epilepsy EEG dataset provided by the University of Bonn is used in this study .
0.99: (The benchmark epilepsy EEG dataset; provided; by the University of Bonn)
1.00: (The benchmark epilepsy EEG dataset; is used; in this study)

The classification performance is evaluated using 10 -fold cross validation .
1.00: (The classification performance; is evaluated; )
1.00: (The classification performance; using; 10 -fold cross validation)

The classifiers used are the Nearest Neighbor ( NN ) , Support Vector Machine ( SVM ) , Decision Tree ( DT ) and Artificial Neural Network ( ANN ) .
1.00: (The classifiers; used; )
0.98: (The classifiers used ( NN ); are; the Nearest Neighbor)
0.97: (The classifiers used ); are; Support Vector Machine)
1.00: (The classifiers used; are; Decision Tree)
0.95: (The classifiers used ); are; Artificial Neural Network)

The experiments have been repeated for 50 times .
1.00: (The experiments; have been repeated; for 50 times)

Results : Neighbor Descriptive Pattern [ LNDP and 1D-LGPfeature extraction techniques with ANN classifier achieved the average classification accuracy of 99.82 % and 99.80 % , respectively , for the classification between normal and epileptic EEG signals .
0.50: (Neighbor Descriptive Pattern [ LNDP techniques with ANN classifier; achieved respectively; the average classification accuracy of 99.82 % and 99.80 % , , for the classification between normal and epileptic EEG signals)
0.45: (with ANN classifier; achieved respectively; the average classification accuracy of 99.82 % and 99.80 % , , for classification)

Eight different experimental cases were tested .
1.00: (Eight different experimental cases; were tested; )

The classification results were better than those of some existing methods .
1.00: (The classification results; were; better than those of some existing methods)

Conclusions : this study suggests that Neighbor Descriptive Pattern [ LNDP and 1D-LGPcould be effective feature extraction techniques for the classification of epileptic EEG signals .
1.00: (this study; suggests; that Neighbor Descriptive Pattern [ LNDP be effective feature extraction techniques for the classification of epileptic EEG signals)
0.91: (Neighbor Descriptive Pattern LNDP; be; effective feature extraction techniques for the classification of epileptic EEG signals)
1.00: (this study; suggests; that Neighbor Descriptive Pattern [ 1D-LGPcould be effective feature extraction techniques for the classification of epileptic EEG signals)
0.98: (Neighbor Descriptive Pattern 1D-LGPcould; be; effective feature extraction techniques for the classification of epileptic EEG signals)

Formal language theory plays , in computer science , a fundamental role that allows , among other things , the development of one of the cornerstones of information technology : programming languages .
0.98: (Formal language theory; plays; in computer science)
0.89: (a fundamental role; allows; among other things)

Formal language theory define the mandatory grammatical rules that programmers need to follow to create the tools that enable humans to interact with machines .
0.99: (Formal language theory; define; the mandatory grammatical rules that programmers need to follow to create the tools)
0.92: (the tools; enable; humans to interact with machines)
0.36: (the mandatory grammatical rules programmers humans; need to interact; to follow to create with machines)
0.53: (the mandatory grammatical rules programmers; need to follow; to create the tools)
0.70: (the mandatory grammatical rules programmers; need to follow to create; the tools that enable humans to interact with machines)

Despite Formal language theory significance , formal language theory is often taken for granted , even by software developers , who regularly follow the rules of their programming domain .
1.00: (formal language theory; is taken; for granted often)
1.00: (software developers; regularly follow; the rules of their programming domain)

Unless the developer is creating the developer own programming language , data structure , or describing the formal background of an existing one , the developer will not need to dive deep into formal languages , grammar or automaton theory .
0.99: (the developer; is creating; the developer own programming language , data structure)
0.00: (the developer; will not need; to dive deep into formal languages)
0.86: (the developer; will not need to dive deep; into formal languages)
1.00: (the developer; will not need; to dive deep into grammar)
0.82: (the developer; will not need to dive deep; into grammar)
1.00: (the developer; will not need; to dive deep into automaton theory)
0.28: (the developer; will not need to dive; deep into automaton theory)
1.00: (the developer; is describing; the formal background of an existing one)
0.38: (the developer; will not need to dive; deep into formal languages)
0.39: (the developer; will not need to dive; deep into grammar)

Those who do need to develop their own rules will first have to understand the theory of formal languages , and the limitations formal languages impose .
0.95: (Those who do need to develop their own rules; to understand; the theory of formal languages)
1.00: (Those; do need; to develop their own rules)
0.99: (Those; do need to develop; their own rules)
0.92: (Those who to develop their own rules; to understand; the limitations formal languages impose)
0.84: (Those the limitations languages; impose; formal)

This paper will do an introduction to the fundamentals of language theory , the fundamentals of language theory classification , restrictions and representation .
1.00: (This paper; will do; an introduction to the fundamentals of language theory , the fundamentals of language theory classification)
1.00: (This paper; will do; an introduction to the fundamentals of language theory , the fundamentals of language theory restrictions)
1.00: (This paper; will do; an introduction to the fundamentals of language theory , the fundamentals of language theory representation)

Once the fundamentals of language theory are set , we will use a worldwide known data structure format such as the JavaScript Object Notation ( JSON ) , to formally define its grammar rules and automaton .
1.00: (the fundamentals of language theory; are set; )
0.98: (we; will use; a worldwide known data structure format such as the JavaScript Object Notation Once the fundamentals of language theory are set)
0.79: (we; will use a worldwide known data structure format such as to formally define; its grammar rules)
0.77: (we; will use a worldwide known data structure format such as to formally define; its automaton)

All of this formal background will allow us to transform theory into bits , by developing an algorithm that will analyze streams of texts , accepting or rejecting streams of texts as streams of texts comply or not with the predefined rules .
0.97: (All of this formal background; will allow; us to transform theory into bits , by developing an algorithm)
0.81: (us; to transform; theory into bits)
0.57: (that will analyze streams of texts , texts as streams of texts; comply; the predefined rules)
0.26: (an algorithm that streams of texts ,; accepting; streams of texts as streams of texts)
0.14: (an algorithm will analyze streams of texts; accepting; streams of texts as streams of texts not with the predefined rules)
0.69: (that will analyze texts , streams of texts; comply; as the predefined rules)
0.31: (an algorithm that streams of texts ,; rejecting; streams of texts as streams of texts comply the predefined rules)

All of this formal background will allow us to transform theory into bits , by developing an algorithm that will analyze streams of texts , accepting or rejecting streams of texts as streams of texts comply or not with the predefined rules .
0.88: (All of this formal background; will allow; us to transform theory into bits , by developing an algorithm)
0.92: (us; to transform; theory into bits)

Finally , we will analyze the outcomes of this implementation , this implementation benefits , limitations , and alternatives that could have been followed .
0.81: (we; will analyze; the outcomes of this implementation , this implementation benefits , limitations , and alternatives Finally)
0.99: (this implementation benefits , limitations , and alternatives; could have been followed; )
