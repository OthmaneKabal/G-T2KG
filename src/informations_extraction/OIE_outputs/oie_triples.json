[
  {
    "sentence": "Computer networks consist of several assets such as hardware , software , and data sources .",
    "subject": "Computer networks",
    "predicate": "consist",
    "object": "of several assets such as hardware",
    "confidence": 1.0
  },
  {
    "sentence": "Computer networks consist of several assets such as hardware , software , and data sources .",
    "subject": "Computer networks",
    "predicate": "consist",
    "object": "of several assets such as software",
    "confidence": 1.0
  },
  {
    "sentence": "Computer networks consist of several assets such as hardware , software , and data sources .",
    "subject": "Computer networks",
    "predicate": "consist",
    "object": "of several assets such as data sources",
    "confidence": 1.0
  },
  {
    "sentence": "several assets such as hardware , software , and data sources have often some vulnerabilities which can be exploited by attackers that violate security policies in Computer networks .",
    "subject": "several assets such as hardware",
    "predicate": "have",
    "object": "often some vulnerabilities which can be exploited by attackers",
    "confidence": 1.0
  },
  {
    "sentence": "several assets such as hardware , software , and data sources have often some vulnerabilities which can be exploited by attackers that violate security policies in Computer networks .",
    "subject": "some vulnerabilities",
    "predicate": "can be exploited",
    "object": "by attackers often",
    "confidence": 0.96
  },
  {
    "sentence": "several assets such as hardware , software , and data sources have often some vulnerabilities which can be exploited by attackers that violate security policies in Computer networks .",
    "subject": "attackers",
    "predicate": "violate",
    "object": "security policies in Computer networks",
    "confidence": 1.0
  },
  {
    "sentence": "several assets such as hardware , software , and data sources have often some vulnerabilities which can be exploited by attackers that violate security policies in Computer networks .",
    "subject": "several assets such as software",
    "predicate": "have",
    "object": "often some vulnerabilities which can be exploited by attackers",
    "confidence": 1.0
  },
  {
    "sentence": "several assets such as hardware , software , and data sources have often some vulnerabilities which can be exploited by attackers that violate security policies in Computer networks .",
    "subject": "several assets such as data sources",
    "predicate": "have",
    "object": "often some vulnerabilities which can be exploited by attackers",
    "confidence": 1.0
  },
  {
    "sentence": "Considering the limited budget , the network administrator should analyze and prioritize some vulnerabilities which can be exploited by attackers that violate security policies in the network to be able to efficiently protect a network by mitigating the most risky ones .",
    "subject": "the network administrator",
    "predicate": "should analyze",
    "object": "some vulnerabilities which can be exploited by attackers",
    "confidence": 1.0
  },
  {
    "sentence": "Considering the limited budget , the network administrator should analyze and prioritize some vulnerabilities which can be exploited by attackers that violate security policies in the network to be able to efficiently protect a network by mitigating the most risky ones .",
    "subject": "some vulnerabilities",
    "predicate": "can be exploited",
    "object": "by attackers",
    "confidence": 0.99
  },
  {
    "sentence": "Considering the limited budget , the network administrator should analyze and prioritize some vulnerabilities which can be exploited by attackers that violate security policies in the network to be able to efficiently protect a network by mitigating the most risky ones .",
    "subject": "attackers",
    "predicate": "violate",
    "object": "security policies in the network network",
    "confidence": 0.71
  },
  {
    "sentence": "Considering the limited budget , the network administrator should analyze and prioritize some vulnerabilities which can be exploited by attackers that violate security policies in the network to be able to efficiently protect a network by mitigating the most risky ones .",
    "subject": "attackers in the network",
    "predicate": "security policies to be",
    "object": "able to efficiently protect a network by mitigating the most risky ones",
    "confidence": 0.16
  },
  {
    "sentence": "Considering the limited budget , the network administrator should analyze and prioritize some vulnerabilities which can be exploited by attackers that violate security policies in the network to be able to efficiently protect a network by mitigating the most risky ones .",
    "subject": "attackers",
    "predicate": "to efficiently protect",
    "object": "a network",
    "confidence": 0.83
  },
  {
    "sentence": "Considering the limited budget , the network administrator should analyze and prioritize some vulnerabilities which can be exploited by attackers that violate security policies in the network to be able to efficiently protect a network by mitigating the most risky ones .",
    "subject": "the network administrator",
    "predicate": "should prioritize",
    "object": "some vulnerabilities which can be exploited by attackers",
    "confidence": 1.0
  },
  {
    "sentence": "Considering the limited budget , the network administrator should analyze and prioritize some vulnerabilities which can be exploited by attackers that violate security policies in the network to be able to efficiently protect a network by mitigating the most risky ones .",
    "subject": "attackers",
    "predicate": "violate",
    "object": "security policies in the network",
    "confidence": 0.95
  },
  {
    "sentence": "Considering the limited budget , the network administrator should analyze and prioritize some vulnerabilities which can be exploited by attackers that violate security policies in the network to be able to efficiently protect a network by mitigating the most risky ones .",
    "subject": "attackers",
    "predicate": "security policies to be",
    "object": "able to efficiently protect a network by mitigating the most risky ones",
    "confidence": 0.8
  },
  {
    "sentence": "Considering the limited budget , the network administrator should analyze and prioritize some vulnerabilities which can be exploited by attackers that violate security policies in the network to be able to efficiently protect a network by mitigating the most risky ones .",
    "subject": "attackers network",
    "predicate": "to efficiently protect",
    "object": "a network",
    "confidence": 0.58
  },
  {
    "sentence": "So far , several security parameters are offered to analyze security risks from the network security administrator 's perspective .",
    "subject": "several security parameters",
    "predicate": "are offered",
    "object": "to analyze security risks from the network security administrator 's perspective So far",
    "confidence": 0.95
  },
  {
    "sentence": "So far , several security parameters are offered to analyze security risks from the network security administrator 's perspective .",
    "subject": "several security parameters",
    "predicate": "to analyze",
    "object": "security risks",
    "confidence": 1.0
  },
  {
    "sentence": "The major drawback of these methods is that these methods do not consider attacker 's motivation .",
    "subject": "The major drawback of these methods",
    "predicate": "is",
    "object": "that these methods do not consider attacker 's motivation",
    "confidence": 0.01
  },
  {
    "sentence": "The major drawback of these methods is that these methods do not consider attacker 's motivation .",
    "subject": "these methods",
    "predicate": "do not consider",
    "object": "attacker 's motivation",
    "confidence": 1.0
  },
  {
    "sentence": "Depending on the motivation of potential attackers , different attack path may be selected for network security compromise .",
    "subject": "different attack path",
    "predicate": "may be selected",
    "object": "for network security compromise",
    "confidence": 1.0
  },
  {
    "sentence": "So , attacker 's motivation is a key factor in predicting the attacker 's behavior .",
    "subject": "attacker 's motivation",
    "predicate": "is",
    "object": "a key factor in predicting the attacker 's behavior",
    "confidence": 1.0
  },
  {
    "sentence": "In this paper , the attacker 's motivation is considered in the process of security risk analysis , so network administrators are able to analyze security risks more accurately .",
    "subject": "the attacker 's motivation network administrators",
    "predicate": "is more",
    "object": "in the process of security risk analysis able to analyze security risks accurately",
    "confidence": 0.43
  },
  {
    "sentence": "In this paper , the attacker 's motivation is considered in the process of security risk analysis , so network administrators are able to analyze security risks more accurately .",
    "subject": "so network administrators",
    "predicate": "are to analyze accurately",
    "object": "able security risks more",
    "confidence": 0.35
  },
  {
    "sentence": "In this paper , the attacker 's motivation is considered in the process of security risk analysis , so network administrators are able to analyze security risks more accurately .",
    "subject": "the attacker 's motivation",
    "predicate": "is considered",
    "object": "In this paper in the process of security risk analysis",
    "confidence": 0.44
  },
  {
    "sentence": "The proposed method is applied on a network and the results are compared with novel works in this area .",
    "subject": "The proposed method",
    "predicate": "is applied",
    "object": "on a network",
    "confidence": 1.0
  },
  {
    "sentence": "The proposed method is applied on a network and the results are compared with novel works in this area .",
    "subject": "the results",
    "predicate": "are compared",
    "object": "with novel works in this area",
    "confidence": 1.0
  },
  {
    "sentence": "The experimental results show that network administrator will be able to precisely predict the behavior of attackers and apply countermeasures more efficiently .",
    "subject": "network administrator",
    "predicate": "to precisely predict",
    "object": "the behavior of attackers",
    "confidence": 1.0
  },
  {
    "sentence": "The experimental results show that network administrator will be able to precisely predict the behavior of attackers and apply countermeasures more efficiently .",
    "subject": "The experimental results",
    "predicate": "show",
    "object": "that network administrator will be able to precisely predict the behavior of attackers",
    "confidence": 1.0
  },
  {
    "sentence": "The experimental results show that network administrator will be able to precisely predict the behavior of attackers and apply countermeasures more efficiently .",
    "subject": "network administrator",
    "predicate": "will be",
    "object": "able to precisely predict the behavior of attackers",
    "confidence": 1.0
  },
  {
    "sentence": "The experimental results show that network administrator will be able to precisely predict the behavior of attackers and apply countermeasures more efficiently .",
    "subject": "network administrator",
    "predicate": "to apply more efficiently",
    "object": "countermeasures",
    "confidence": 0.99
  },
  {
    "sentence": "The experimental results show that network administrator will be able to precisely predict the behavior of attackers and apply countermeasures more efficiently .",
    "subject": "The experimental results",
    "predicate": "show",
    "object": "that network administrator will be able to apply countermeasures more efficiently",
    "confidence": 1.0
  },
  {
    "sentence": "The experimental results show that network administrator will be able to precisely predict the behavior of attackers and apply countermeasures more efficiently .",
    "subject": "network administrator",
    "predicate": "will be",
    "object": "able to apply countermeasures more efficiently",
    "confidence": 1.0
  },
  {
    "sentence": "Background and objective : According to the World Health Organization ( WHO ) epilepsy affects approximately 45-50 million people .",
    "subject": "epilepsy",
    "predicate": "affects",
    "object": "approximately 45-50 million people",
    "confidence": 1.0
  },
  {
    "sentence": "Background and objective : According to the World Health Organization ( WHO ) epilepsy affects approximately 45-50 million people .",
    "subject": "epilepsy",
    "predicate": "affects",
    "object": "approximately 45-50 million people World",
    "confidence": 0.98
  },
  {
    "sentence": "Electroencephalogram ( EEG ) records the neurological activity in the brain and Electroencephalogram ( EEG ) is used to identify epilepsy .",
    "subject": "Electroencephalogram",
    "predicate": "records",
    "object": "the neurological activity in the brain",
    "confidence": 1.0
  },
  {
    "sentence": "Electroencephalogram ( EEG ) records the neurological activity in the brain and Electroencephalogram ( EEG ) is used to identify epilepsy .",
    "subject": "Electroencephalogram",
    "predicate": "is used",
    "object": "to identify epilepsy",
    "confidence": 1.0
  },
  {
    "sentence": "Electroencephalogram ( EEG ) records the neurological activity in the brain and Electroencephalogram ( EEG ) is used to identify epilepsy .",
    "subject": "Electroencephalogram",
    "predicate": "to identify",
    "object": "epilepsy",
    "confidence": 1.0
  },
  {
    "sentence": "Visual inspection of EEG signals is a time-consuming process and Visual inspection of EEG signals may lead to human error .",
    "subject": "Visual inspection of EEG signals",
    "predicate": "is",
    "object": "a time-consuming process",
    "confidence": 1.0
  },
  {
    "sentence": "Visual inspection of EEG signals is a time-consuming process and Visual inspection of EEG signals may lead to human error .",
    "subject": "Visual inspection of EEG signals",
    "predicate": "may lead",
    "object": "to human error",
    "confidence": 1.0
  },
  {
    "sentence": "Feature extraction and classification are two main steps that are required to build an automated epilepsy detection framework .",
    "subject": "Feature extraction",
    "predicate": "are",
    "object": "two main steps that are required to build an automated epilepsy detection framework",
    "confidence": 1.0
  },
  {
    "sentence": "Feature extraction and classification are two main steps that are required to build an automated epilepsy detection framework .",
    "subject": "two main steps",
    "predicate": "are required",
    "object": "to build an automated epilepsy detection framework",
    "confidence": 1.0
  },
  {
    "sentence": "Feature extraction and classification are two main steps that are required to build an automated epilepsy detection framework .",
    "subject": "two main steps",
    "predicate": "to build",
    "object": "an automated epilepsy detection framework",
    "confidence": 1.0
  },
  {
    "sentence": "Feature extraction and classification are two main steps that are required to build an automated epilepsy detection framework .",
    "subject": "classification",
    "predicate": "are",
    "object": "two main steps that are required to build an automated epilepsy detection framework",
    "confidence": 0.01
  },
  {
    "sentence": "Feature extraction reduces the dimensions of the input signal by retaining informative features and the classifier assigns a proper class label to the extracted feature vector .",
    "subject": "Feature extraction",
    "predicate": "reduces",
    "object": "the dimensions of the input signal by retaining informative features",
    "confidence": 1.0
  },
  {
    "sentence": "Feature extraction reduces the dimensions of the input signal by retaining informative features and the classifier assigns a proper class label to the extracted feature vector .",
    "subject": "the classifier",
    "predicate": "assigns",
    "object": "a proper class label to the extracted feature vector",
    "confidence": 1.0
  },
  {
    "sentence": "Our aim is to present effective feature extraction techniques for automated epileptic EEG signal classification .",
    "subject": "Our aim",
    "predicate": "is",
    "object": "to present effective feature extraction techniques for automated epileptic EEG signal classification",
    "confidence": 1.0
  },
  {
    "sentence": "Neighbor Descriptive Pattern [ LNDP ] and One-dimensional Local Gradient Pattern [ 1D-LGP ] ) have been introduced to classify epileptic EEG signals .",
    "subject": "Neighbor Descriptive Pattern",
    "predicate": "have been introduced",
    "object": "to classify epileptic EEG signals",
    "confidence": 1.0
  },
  {
    "sentence": "Neighbor Descriptive Pattern [ LNDP ] and One-dimensional Local Gradient Pattern [ 1D-LGP ] ) have been introduced to classify epileptic EEG signals .",
    "subject": "Neighbor Descriptive Pattern",
    "predicate": "to classify",
    "object": "epileptic EEG signals",
    "confidence": 0.97
  },
  {
    "sentence": "Neighbor Descriptive Pattern [ LNDP ] and One-dimensional Local Gradient Pattern [ 1D-LGP ] ) have been introduced to classify epileptic EEG signals .",
    "subject": "One-dimensional Local Gradient Pattern",
    "predicate": "have been introduced",
    "object": "to classify epileptic EEG signals",
    "confidence": 1.0
  },
  {
    "sentence": "Neighbor Descriptive Pattern [ LNDP ] and One-dimensional Local Gradient Pattern [ 1D-LGP ] ) have been introduced to classify epileptic EEG signals .",
    "subject": "One-dimensional Local Gradient Pattern",
    "predicate": "to classify",
    "object": "epileptic EEG signals",
    "confidence": 0.89
  },
  {
    "sentence": "The classification between epileptic seizure and non -seizure signals is performed using different machine learning classifiers .",
    "subject": "The classification between epileptic seizure and non -seizure signals",
    "predicate": "is performed",
    "object": "using different machine learning",
    "confidence": 0.92
  },
  {
    "sentence": "The benchmark epilepsy EEG dataset provided by the University of Bonn is used in this study .",
    "subject": "The benchmark epilepsy EEG dataset",
    "predicate": "provided",
    "object": "by the University of Bonn",
    "confidence": 0.99
  },
  {
    "sentence": "The benchmark epilepsy EEG dataset provided by the University of Bonn is used in this study .",
    "subject": "The benchmark epilepsy EEG dataset",
    "predicate": "is used",
    "object": "in this study",
    "confidence": 1.0
  },
  {
    "sentence": "The classification performance is evaluated using 10 -fold cross validation .",
    "subject": "The classification performance",
    "predicate": "is evaluated",
    "object": "",
    "confidence": 1.0
  },
  {
    "sentence": "The classification performance is evaluated using 10 -fold cross validation .",
    "subject": "The classification performance",
    "predicate": "using",
    "object": "10 -fold cross validation",
    "confidence": 1.0
  },
  {
    "sentence": "The classifiers used are the Nearest Neighbor ( NN ) , Support Vector Machine ( SVM ) , Decision Tree ( DT ) and Artificial Neural Network ( ANN ) .",
    "subject": "The classifiers",
    "predicate": "used",
    "object": "",
    "confidence": 1.0
  },
  {
    "sentence": "The classifiers used are the Nearest Neighbor ( NN ) , Support Vector Machine ( SVM ) , Decision Tree ( DT ) and Artificial Neural Network ( ANN ) .",
    "subject": "The classifiers used ( NN )",
    "predicate": "are",
    "object": "the Nearest Neighbor",
    "confidence": 0.98
  },
  {
    "sentence": "The classifiers used are the Nearest Neighbor ( NN ) , Support Vector Machine ( SVM ) , Decision Tree ( DT ) and Artificial Neural Network ( ANN ) .",
    "subject": "The classifiers used )",
    "predicate": "are",
    "object": "Support Vector Machine",
    "confidence": 0.97
  },
  {
    "sentence": "The classifiers used are the Nearest Neighbor ( NN ) , Support Vector Machine ( SVM ) , Decision Tree ( DT ) and Artificial Neural Network ( ANN ) .",
    "subject": "The classifiers used",
    "predicate": "are",
    "object": "Decision Tree",
    "confidence": 1.0
  },
  {
    "sentence": "The classifiers used are the Nearest Neighbor ( NN ) , Support Vector Machine ( SVM ) , Decision Tree ( DT ) and Artificial Neural Network ( ANN ) .",
    "subject": "The classifiers used )",
    "predicate": "are",
    "object": "Artificial Neural Network",
    "confidence": 0.95
  },
  {
    "sentence": "The experiments have been repeated for 50 times .",
    "subject": "The experiments",
    "predicate": "have been repeated",
    "object": "for 50 times",
    "confidence": 1.0
  },
  {
    "sentence": "Results : Neighbor Descriptive Pattern [ LNDP and 1D-LGPfeature extraction techniques with ANN classifier achieved the average classification accuracy of 99.82 % and 99.80 % , respectively , for the classification between normal and epileptic EEG signals .",
    "subject": "Neighbor Descriptive Pattern [ LNDP techniques with ANN classifier",
    "predicate": "achieved respectively",
    "object": "the average classification accuracy of 99.82 % and 99.80 % , , for the classification between normal and epileptic EEG signals",
    "confidence": 0.5
  },
  {
    "sentence": "Results : Neighbor Descriptive Pattern [ LNDP and 1D-LGPfeature extraction techniques with ANN classifier achieved the average classification accuracy of 99.82 % and 99.80 % , respectively , for the classification between normal and epileptic EEG signals .",
    "subject": "with ANN classifier",
    "predicate": "achieved respectively",
    "object": "the average classification accuracy of 99.82 % and 99.80 % , , for classification",
    "confidence": 0.45
  },
  {
    "sentence": "Eight different experimental cases were tested .",
    "subject": "Eight different experimental cases",
    "predicate": "were tested",
    "object": "",
    "confidence": 1.0
  },
  {
    "sentence": "The classification results were better than those of some existing methods .",
    "subject": "The classification results",
    "predicate": "were",
    "object": "better than those of some existing methods",
    "confidence": 1.0
  },
  {
    "sentence": "Conclusions : this study suggests that Neighbor Descriptive Pattern [ LNDP and 1D-LGPcould be effective feature extraction techniques for the classification of epileptic EEG signals .",
    "subject": "this study",
    "predicate": "suggests",
    "object": "that Neighbor Descriptive Pattern [ LNDP be effective feature extraction techniques for the classification of epileptic EEG signals",
    "confidence": 1.0
  },
  {
    "sentence": "Conclusions : this study suggests that Neighbor Descriptive Pattern [ LNDP and 1D-LGPcould be effective feature extraction techniques for the classification of epileptic EEG signals .",
    "subject": "Neighbor Descriptive Pattern LNDP",
    "predicate": "be",
    "object": "effective feature extraction techniques for the classification of epileptic EEG signals",
    "confidence": 0.91
  },
  {
    "sentence": "Conclusions : this study suggests that Neighbor Descriptive Pattern [ LNDP and 1D-LGPcould be effective feature extraction techniques for the classification of epileptic EEG signals .",
    "subject": "this study",
    "predicate": "suggests",
    "object": "that Neighbor Descriptive Pattern [ 1D-LGPcould be effective feature extraction techniques for the classification of epileptic EEG signals",
    "confidence": 1.0
  },
  {
    "sentence": "Conclusions : this study suggests that Neighbor Descriptive Pattern [ LNDP and 1D-LGPcould be effective feature extraction techniques for the classification of epileptic EEG signals .",
    "subject": "Neighbor Descriptive Pattern 1D-LGPcould",
    "predicate": "be",
    "object": "effective feature extraction techniques for the classification of epileptic EEG signals",
    "confidence": 0.98
  },
  {
    "sentence": "Formal language theory plays , in computer science , a fundamental role that allows , among other things , the development of one of the cornerstones of information technology : programming languages .",
    "subject": "Formal language theory",
    "predicate": "plays",
    "object": "in computer science",
    "confidence": 0.98
  },
  {
    "sentence": "Formal language theory plays , in computer science , a fundamental role that allows , among other things , the development of one of the cornerstones of information technology : programming languages .",
    "subject": "a fundamental role",
    "predicate": "allows",
    "object": "among other things",
    "confidence": 0.89
  },
  {
    "sentence": "Formal language theory define the mandatory grammatical rules that programmers need to follow to create the tools that enable humans to interact with machines .",
    "subject": "Formal language theory",
    "predicate": "define",
    "object": "the mandatory grammatical rules that programmers need to follow to create the tools",
    "confidence": 0.99
  },
  {
    "sentence": "Formal language theory define the mandatory grammatical rules that programmers need to follow to create the tools that enable humans to interact with machines .",
    "subject": "the tools",
    "predicate": "enable",
    "object": "humans to interact with machines",
    "confidence": 0.92
  },
  {
    "sentence": "Formal language theory define the mandatory grammatical rules that programmers need to follow to create the tools that enable humans to interact with machines .",
    "subject": "the mandatory grammatical rules programmers humans",
    "predicate": "need to interact",
    "object": "to follow to create with machines",
    "confidence": 0.36
  },
  {
    "sentence": "Formal language theory define the mandatory grammatical rules that programmers need to follow to create the tools that enable humans to interact with machines .",
    "subject": "the mandatory grammatical rules programmers",
    "predicate": "need to follow",
    "object": "to create the tools",
    "confidence": 0.53
  },
  {
    "sentence": "Formal language theory define the mandatory grammatical rules that programmers need to follow to create the tools that enable humans to interact with machines .",
    "subject": "the mandatory grammatical rules programmers",
    "predicate": "need to follow to create",
    "object": "the tools that enable humans to interact with machines",
    "confidence": 0.7
  },
  {
    "sentence": "Despite Formal language theory significance , formal language theory is often taken for granted , even by software developers , who regularly follow the rules of their programming domain .",
    "subject": "formal language theory",
    "predicate": "is taken",
    "object": "for granted often",
    "confidence": 1.0
  },
  {
    "sentence": "Despite Formal language theory significance , formal language theory is often taken for granted , even by software developers , who regularly follow the rules of their programming domain .",
    "subject": "software developers",
    "predicate": "regularly follow",
    "object": "the rules of their programming domain",
    "confidence": 1.0
  },
  {
    "sentence": "Unless the developer is creating the developer own programming language , data structure , or describing the formal background of an existing one , the developer will not need to dive deep into formal languages , grammar or automaton theory .",
    "subject": "the developer",
    "predicate": "is creating",
    "object": "the developer own programming language , data structure",
    "confidence": 0.99
  },
  {
    "sentence": "Unless the developer is creating the developer own programming language , data structure , or describing the formal background of an existing one , the developer will not need to dive deep into formal languages , grammar or automaton theory .",
    "subject": "the developer",
    "predicate": "will not need",
    "object": "to dive deep into formal languages",
    "confidence": 0.0
  },
  {
    "sentence": "Unless the developer is creating the developer own programming language , data structure , or describing the formal background of an existing one , the developer will not need to dive deep into formal languages , grammar or automaton theory .",
    "subject": "the developer",
    "predicate": "will not need to dive deep",
    "object": "into formal languages",
    "confidence": 0.86
  },
  {
    "sentence": "Unless the developer is creating the developer own programming language , data structure , or describing the formal background of an existing one , the developer will not need to dive deep into formal languages , grammar or automaton theory .",
    "subject": "the developer",
    "predicate": "will not need",
    "object": "to dive deep into grammar",
    "confidence": 1.0
  },
  {
    "sentence": "Unless the developer is creating the developer own programming language , data structure , or describing the formal background of an existing one , the developer will not need to dive deep into formal languages , grammar or automaton theory .",
    "subject": "the developer",
    "predicate": "will not need to dive deep",
    "object": "into grammar",
    "confidence": 0.82
  },
  {
    "sentence": "Unless the developer is creating the developer own programming language , data structure , or describing the formal background of an existing one , the developer will not need to dive deep into formal languages , grammar or automaton theory .",
    "subject": "the developer",
    "predicate": "will not need",
    "object": "to dive deep into automaton theory",
    "confidence": 1.0
  },
  {
    "sentence": "Unless the developer is creating the developer own programming language , data structure , or describing the formal background of an existing one , the developer will not need to dive deep into formal languages , grammar or automaton theory .",
    "subject": "the developer",
    "predicate": "will not need to dive",
    "object": "deep into automaton theory",
    "confidence": 0.28
  },
  {
    "sentence": "Unless the developer is creating the developer own programming language , data structure , or describing the formal background of an existing one , the developer will not need to dive deep into formal languages , grammar or automaton theory .",
    "subject": "the developer",
    "predicate": "is describing",
    "object": "the formal background of an existing one",
    "confidence": 1.0
  },
  {
    "sentence": "Unless the developer is creating the developer own programming language , data structure , or describing the formal background of an existing one , the developer will not need to dive deep into formal languages , grammar or automaton theory .",
    "subject": "the developer",
    "predicate": "will not need to dive",
    "object": "deep into formal languages",
    "confidence": 0.38
  },
  {
    "sentence": "Unless the developer is creating the developer own programming language , data structure , or describing the formal background of an existing one , the developer will not need to dive deep into formal languages , grammar or automaton theory .",
    "subject": "the developer",
    "predicate": "will not need to dive",
    "object": "deep into grammar",
    "confidence": 0.39
  },
  {
    "sentence": "Those who do need to develop their own rules will first have to understand the theory of formal languages , and the limitations formal languages impose .",
    "subject": "Those who do need to develop their own rules",
    "predicate": "to understand",
    "object": "the theory of formal languages",
    "confidence": 0.95
  },
  {
    "sentence": "Those who do need to develop their own rules will first have to understand the theory of formal languages , and the limitations formal languages impose .",
    "subject": "Those",
    "predicate": "do need",
    "object": "to develop their own rules",
    "confidence": 1.0
  },
  {
    "sentence": "Those who do need to develop their own rules will first have to understand the theory of formal languages , and the limitations formal languages impose .",
    "subject": "Those",
    "predicate": "do need to develop",
    "object": "their own rules",
    "confidence": 0.99
  },
  {
    "sentence": "Those who do need to develop their own rules will first have to understand the theory of formal languages , and the limitations formal languages impose .",
    "subject": "Those who to develop their own rules",
    "predicate": "to understand",
    "object": "the limitations formal languages impose",
    "confidence": 0.92
  },
  {
    "sentence": "Those who do need to develop their own rules will first have to understand the theory of formal languages , and the limitations formal languages impose .",
    "subject": "Those the limitations languages",
    "predicate": "impose",
    "object": "formal",
    "confidence": 0.84
  },
  {
    "sentence": "This paper will do an introduction to the fundamentals of language theory , the fundamentals of language theory classification , restrictions and representation .",
    "subject": "This paper",
    "predicate": "will do",
    "object": "an introduction to the fundamentals of language theory , the fundamentals of language theory classification",
    "confidence": 1.0
  },
  {
    "sentence": "This paper will do an introduction to the fundamentals of language theory , the fundamentals of language theory classification , restrictions and representation .",
    "subject": "This paper",
    "predicate": "will do",
    "object": "an introduction to the fundamentals of language theory , the fundamentals of language theory restrictions",
    "confidence": 1.0
  },
  {
    "sentence": "This paper will do an introduction to the fundamentals of language theory , the fundamentals of language theory classification , restrictions and representation .",
    "subject": "This paper",
    "predicate": "will do",
    "object": "an introduction to the fundamentals of language theory , the fundamentals of language theory representation",
    "confidence": 1.0
  },
  {
    "sentence": "Once the fundamentals of language theory are set , we will use a worldwide known data structure format such as the JavaScript Object Notation ( JSON ) , to formally define its grammar rules and automaton .",
    "subject": "the fundamentals of language theory",
    "predicate": "are set",
    "object": "",
    "confidence": 1.0
  },
  {
    "sentence": "Once the fundamentals of language theory are set , we will use a worldwide known data structure format such as the JavaScript Object Notation ( JSON ) , to formally define its grammar rules and automaton .",
    "subject": "we",
    "predicate": "will use",
    "object": "a worldwide known data structure format such as the JavaScript Object Notation Once the fundamentals of language theory are set",
    "confidence": 0.98
  },
  {
    "sentence": "Once the fundamentals of language theory are set , we will use a worldwide known data structure format such as the JavaScript Object Notation ( JSON ) , to formally define its grammar rules and automaton .",
    "subject": "we",
    "predicate": "will use a worldwide known data structure format such as to formally define",
    "object": "its grammar rules",
    "confidence": 0.79
  },
  {
    "sentence": "Once the fundamentals of language theory are set , we will use a worldwide known data structure format such as the JavaScript Object Notation ( JSON ) , to formally define its grammar rules and automaton .",
    "subject": "we",
    "predicate": "will use a worldwide known data structure format such as to formally define",
    "object": "its automaton",
    "confidence": 0.77
  },
  {
    "sentence": "All of this formal background will allow us to transform theory into bits , by developing an algorithm that will analyze streams of texts , accepting or rejecting streams of texts as streams of texts comply or not with the predefined rules .",
    "subject": "All of this formal background",
    "predicate": "will allow",
    "object": "us to transform theory into bits , by developing an algorithm",
    "confidence": 0.97
  },
  {
    "sentence": "All of this formal background will allow us to transform theory into bits , by developing an algorithm that will analyze streams of texts , accepting or rejecting streams of texts as streams of texts comply or not with the predefined rules .",
    "subject": "us",
    "predicate": "to transform",
    "object": "theory into bits",
    "confidence": 0.81
  },
  {
    "sentence": "All of this formal background will allow us to transform theory into bits , by developing an algorithm that will analyze streams of texts , accepting or rejecting streams of texts as streams of texts comply or not with the predefined rules .",
    "subject": "that will analyze streams of texts , texts as streams of texts",
    "predicate": "comply",
    "object": "the predefined rules",
    "confidence": 0.57
  },
  {
    "sentence": "All of this formal background will allow us to transform theory into bits , by developing an algorithm that will analyze streams of texts , accepting or rejecting streams of texts as streams of texts comply or not with the predefined rules .",
    "subject": "an algorithm that streams of texts ,",
    "predicate": "accepting",
    "object": "streams of texts as streams of texts",
    "confidence": 0.26
  },
  {
    "sentence": "All of this formal background will allow us to transform theory into bits , by developing an algorithm that will analyze streams of texts , accepting or rejecting streams of texts as streams of texts comply or not with the predefined rules .",
    "subject": "an algorithm will analyze streams of texts",
    "predicate": "accepting",
    "object": "streams of texts as streams of texts not with the predefined rules",
    "confidence": 0.14
  },
  {
    "sentence": "All of this formal background will allow us to transform theory into bits , by developing an algorithm that will analyze streams of texts , accepting or rejecting streams of texts as streams of texts comply or not with the predefined rules .",
    "subject": "that will analyze texts , streams of texts",
    "predicate": "comply",
    "object": "as the predefined rules",
    "confidence": 0.69
  },
  {
    "sentence": "All of this formal background will allow us to transform theory into bits , by developing an algorithm that will analyze streams of texts , accepting or rejecting streams of texts as streams of texts comply or not with the predefined rules .",
    "subject": "an algorithm that streams of texts ,",
    "predicate": "rejecting",
    "object": "streams of texts as streams of texts comply the predefined rules",
    "confidence": 0.31
  },
  {
    "sentence": "All of this formal background will allow us to transform theory into bits , by developing an algorithm that will analyze streams of texts , accepting or rejecting streams of texts as streams of texts comply or not with the predefined rules .",
    "subject": "All of this formal background",
    "predicate": "will allow",
    "object": "us to transform theory into bits , by developing an algorithm",
    "confidence": 0.88
  },
  {
    "sentence": "All of this formal background will allow us to transform theory into bits , by developing an algorithm that will analyze streams of texts , accepting or rejecting streams of texts as streams of texts comply or not with the predefined rules .",
    "subject": "us",
    "predicate": "to transform",
    "object": "theory into bits",
    "confidence": 0.92
  },
  {
    "sentence": "Finally , we will analyze the outcomes of this implementation , this implementation benefits , limitations , and alternatives that could have been followed .",
    "subject": "we",
    "predicate": "will analyze",
    "object": "the outcomes of this implementation , this implementation benefits , limitations , and alternatives Finally",
    "confidence": 0.81
  },
  {
    "sentence": "Finally , we will analyze the outcomes of this implementation , this implementation benefits , limitations , and alternatives that could have been followed .",
    "subject": "this implementation benefits , limitations , and alternatives",
    "predicate": "could have been followed",
    "object": "",
    "confidence": 0.99
  }
]