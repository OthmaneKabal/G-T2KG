[
  {
    "subject": "A common way to learn",
    "predicate": "is by",
    "object": "studying written step-by-step tutorials",
    "sentence": " A common way to learn is by studying written step-by-step tutorials such as worked examples.",
    "id": "00026"
  },
  {
    "subject": "A common way to learn",
    "predicate": "is by",
    "object": "studying worked examples",
    "sentence": " A common way to learn is by studying written step-by-step tutorials such as worked examples.",
    "id": "00026"
  },
  {
    "subject": "tutorials for computer programming",
    "predicate": "can be",
    "object": "tedious to create",
    "sentence": "However, tutorials for computer programming can be tedious to create since a static text-based format cannot convey what happens as code executes.",
    "id": "00026"
  },
  {
    "subject": "a static text-based format",
    "predicate": "cannot convey",
    "object": "what happens as code executes",
    "sentence": "However, tutorials for computer programming can be tedious to create since a static text-based format cannot convey what happens as code executes.",
    "id": "00026"
  },
  {
    "subject": "We",
    "predicate": "created",
    "object": "a system called Codepourri",
    "sentence": "We created a system called Codepourri that enables people to easily create visual coding tutorials by annotating steps in an automatically-generated program visualization.",
    "id": "00026"
  },
  {
    "subject": "Codepourri",
    "predicate": "enables",
    "object": "people to easily create visual coding tutorials",
    "sentence": "We created a system called Codepourri that enables people to easily create visual coding tutorials by annotating steps in an automatically-generated program visualization.",
    "id": "00026"
  },
  {
    "subject": "People",
    "predicate": "create",
    "object": "visual coding tutorials by annotating steps",
    "sentence": "We created a system called Codepourri that enables people to easily create visual coding tutorials by annotating steps in an automatically-generated program visualization.",
    "id": "00026"
  },
  {
    "subject": "Steps",
    "predicate": "in",
    "object": "an automatically-generated program visualization",
    "sentence": "We created a system called Codepourri that enables people to easily create visual coding tutorials by annotating steps in an automatically-generated program visualization.",
    "id": "00026"
  },
  {
    "subject": "we",
    "predicate": "developed",
    "object": "a novel crowdsourcing workflow using Codepourri",
    "sentence": "Using Codepourri, we developed a novel crowdsourcing workflow where learners who are visiting an educational website (www.pythontutor.com) collectively create a tutorial by annotating execution steps in a piece of code and then voting on the best annotations.",
    "id": "00026"
  },
  {
    "subject": "learners",
    "predicate": "visiting",
    "object": "an educational website (www.pythontutor.com)",
    "sentence": "Using Codepourri, we developed a novel crowdsourcing workflow where learners who are visiting an educational website (www.pythontutor.com) collectively create a tutorial by annotating execution steps in a piece of code and then voting on the best annotations.",
    "id": "00026"
  },
  {
    "subject": "learners",
    "predicate": "create",
    "object": "a tutorial",
    "sentence": "Using Codepourri, we developed a novel crowdsourcing workflow where learners who are visiting an educational website (www.pythontutor.com) collectively create a tutorial by annotating execution steps in a piece of code and then voting on the best annotations.",
    "id": "00026"
  },
  {
    "subject": "learners",
    "predicate": "annotating",
    "object": "execution steps in a piece of code",
    "sentence": "Using Codepourri, we developed a novel crowdsourcing workflow where learners who are visiting an educational website (www.pythontutor.com) collectively create a tutorial by annotating execution steps in a piece of code and then voting on the best annotations.",
    "id": "00026"
  },
  {
    "subject": "learners",
    "predicate": "voting on",
    "object": "the best annotations",
    "sentence": "Using Codepourri, we developed a novel crowdsourcing workflow where learners who are visiting an educational website (www.pythontutor.com) collectively create a tutorial by annotating execution steps in a piece of code and then voting on the best annotations.",
    "id": "00026"
  },
  {
    "subject": "learners",
    "predicate": "are more than",
    "object": "experts",
    "sentence": "Since there are far more learners than experts, using learners as a crowd is a potentially more scalable way of creating tutorials.",
    "id": "00026"
  },
  {
    "subject": "learners",
    "predicate": "used as",
    "object": "a crowd",
    "sentence": "Since there are far more learners than experts, using learners as a crowd is a potentially more scalable way of creating tutorials.",
    "id": "00026"
  },
  {
    "subject": "using learners as a crowd",
    "predicate": "is",
    "object": "a potentially more scalable way of creating tutorials",
    "sentence": "Since there are far more learners than experts, using learners as a crowd is a potentially more scalable way of creating tutorials.",
    "id": "00026"
  },
  {
    "subject": "Our experiments",
    "predicate": "with",
    "object": "4 expert judges and 101 learners",
    "sentence": "Our experiments with 4 expert judges and 101 learners adding 145 raw annotations to two pieces of textbook Python code show the learner crowd's annotations to be accurate, informative, and containing some insights that even experts missed.",
    "id": "00026"
  },
  {
    "subject": "4 expert judges and 101 learners",
    "predicate": "adding",
    "object": "145 raw annotations to two pieces of textbook Python code",
    "sentence": "Our experiments with 4 expert judges and 101 learners adding 145 raw annotations to two pieces of textbook Python code show the learner crowd's annotations to be accurate, informative, and containing some insights that even experts missed.",
    "id": "00026"
  },
  {
    "subject": "the learner crowd's annotations",
    "predicate": "show",
    "object": "to be accurate, informative",
    "sentence": "Our experiments with 4 expert judges and 101 learners adding 145 raw annotations to two pieces of textbook Python code show the learner crowd's annotations to be accurate, informative, and containing some insights that even experts missed.",
    "id": "00026"
  },
  {
    "subject": "the learner crowd's annotations",
    "predicate": "contain",
    "object": "some insights that even experts missed",
    "sentence": "Our experiments with 4 expert judges and 101 learners adding 145 raw annotations to two pieces of textbook Python code show the learner crowd's annotations to be accurate, informative, and containing some insights that even experts missed.",
    "id": "00026"
  },
  {
    "subject": "conventional power systems",
    "predicate": "turn towards",
    "object": "smart grids (SGs)",
    "sentence": " As the conventional power systems turn towards smart grids (SGs) on a fast pace, this transition may create new and significant challenges to the existing electrical network security.",
    "id": "00438"
  },
  {
    "subject": "this transition",
    "predicate": "may create",
    "object": "new and significant challenges",
    "sentence": " As the conventional power systems turn towards smart grids (SGs) on a fast pace, this transition may create new and significant challenges to the existing electrical network security.",
    "id": "00438"
  },
  {
    "subject": "new and significant challenges",
    "predicate": "to",
    "object": "the existing electrical network security",
    "sentence": " As the conventional power systems turn towards smart grids (SGs) on a fast pace, this transition may create new and significant challenges to the existing electrical network security.",
    "id": "00438"
  },
  {
    "subject": "cyber security",
    "predicate": "has emerged to be",
    "object": "a critical issue",
    "sentence": "Along with many important features of the SGs cyber security has emerged to be a critical issue due to the interconnection of several loads, generators, and renewable resources through the communication network.",
    "id": "00438"
  },
  {
    "subject": "interconnection",
    "predicate": "of",
    "object": "several loads, generators, and renewable resources",
    "sentence": "Along with many important features of the SGs cyber security has emerged to be a critical issue due to the interconnection of several loads, generators, and renewable resources through the communication network.",
    "id": "00438"
  },
  {
    "subject": "interconnection",
    "predicate": "through",
    "object": "the communication network",
    "sentence": "Along with many important features of the SGs cyber security has emerged to be a critical issue due to the interconnection of several loads, generators, and renewable resources through the communication network.",
    "id": "00438"
  },
  {
    "subject": "Cyber-physical attacks (CPAs)",
    "predicate": "are classified as",
    "object": "the major threatening of SGs security",
    "sentence": "Cyber-physical attacks (CPAs) are classified as the major threatening of SGs security because it may lead to severe consequences such as large blackout and destruction of infrastructures.",
    "id": "00438"
  },
  {
    "subject": "Cyber-physical attacks (CPAs)",
    "predicate": "may lead to",
    "object": "severe consequences such as large blackout and destruction of infrastructures",
    "sentence": "Cyber-physical attacks (CPAs) are classified as the major threatening of SGs security because it may lead to severe consequences such as large blackout and destruction of infrastructures.",
    "id": "00438"
  },
  {
    "subject": "Cyber switching attacks (CSAs)",
    "predicate": "attract",
    "object": "the attention due to its severity and speed in destabilizing the SGs",
    "sentence": "Cyber switching attacks (CSAs) (as a part CPAs) start to attract the attention due to its severity and speed in destabilizing the SGs, we present in this paper Thyristor-Controlled Braking Resistor (TCBR) as a solution to mitigate this type of attack.",
    "id": "00438"
  },
  {
    "subject": "Thyristor-Controlled Braking Resistor (TCBR)",
    "predicate": "presented as",
    "object": "a solution to mitigate this type of attack",
    "sentence": "Cyber switching attacks (CSAs) (as a part CPAs) start to attract the attention due to its severity and speed in destabilizing the SGs, we present in this paper Thyristor-Controlled Braking Resistor (TCBR) as a solution to mitigate this type of attack.",
    "id": "00438"
  },
  {
    "subject": "TCBR",
    "predicate": "can enable us to stabilize",
    "object": "the target generator",
    "sentence": "TCBR can enable us to stabilize the target generator in a relatively short time.",
    "id": "00438"
  },
  {
    "subject": "World Health Organization (WHO)",
    "predicate": "states",
    "object": "epilepsy affects approximately 45-50 million people",
    "sentence": " Background and objective: According to the World Health Organization (WHO) epilepsy affects approximately 45-50 million people.",
    "id": "00519"
  },
  {
    "subject": "Electroencephalogram (EEG)",
    "predicate": "records",
    "object": "the neurological activity in the brain",
    "sentence": "Electroencephalogram (EEG) records the neurological activity in the brain and it is used to identify epilepsy.",
    "id": "00519"
  },
  {
    "subject": "Electroencephalogram (EEG)",
    "predicate": "is used to",
    "object": "identify epilepsy",
    "sentence": "Electroencephalogram (EEG) records the neurological activity in the brain and it is used to identify epilepsy.",
    "id": "00519"
  },
  {
    "subject": "Visual inspection of EEG signals",
    "predicate": "is",
    "object": "a time-consuming process",
    "sentence": "Visual inspection of EEG signals is a time-consuming process and it may lead to human error.",
    "id": "00519"
  },
  {
    "subject": "Visual inspection of EEG signals",
    "predicate": "may lead to",
    "object": "human error",
    "sentence": "Visual inspection of EEG signals is a time-consuming process and it may lead to human error.",
    "id": "00519"
  },
  {
    "subject": "Feature extraction and classification",
    "predicate": "are",
    "object": "two main steps required to build an automated epilepsy detection framework",
    "sentence": "Feature extraction and classification are two main steps that are required to build an automated epilepsy detection framework.",
    "id": "00519"
  },
  {
    "subject": "Feature extraction",
    "predicate": "reduces",
    "object": "the dimensions of the input signal",
    "sentence": "Feature extraction reduces the dimensions of the input signal by retaining informative features and the classifier assigns a proper class label to the extracted feature vector.",
    "id": "00519"
  },
  {
    "subject": "Feature extraction",
    "predicate": "retains",
    "object": "informative features",
    "sentence": "Feature extraction reduces the dimensions of the input signal by retaining informative features and the classifier assigns a proper class label to the extracted feature vector.",
    "id": "00519"
  },
  {
    "subject": "the classifier",
    "predicate": "assigns",
    "object": "a proper class label to the extracted feature vector",
    "sentence": "Feature extraction reduces the dimensions of the input signal by retaining informative features and the classifier assigns a proper class label to the extracted feature vector.",
    "id": "00519"
  },
  {
    "subject": "Our aim",
    "predicate": "is to present",
    "object": "effective feature extraction techniques for automated epileptic EEG signal classification",
    "sentence": "Our aim is to present effective feature extraction techniques for automated epileptic EEG signal classification.",
    "id": "00519"
  },
  {
    "subject": "this study",
    "predicate": "uses",
    "object": "two effective feature extraction techniques",
    "sentence": "Methods: In this study, two effective feature extraction techniques (Local.",
    "id": "00519"
  },
  {
    "subject": "Neighbor Descriptive Pattern [LNDP] and One-dimensional Local Gradient Pattern [1D-LGP]",
    "predicate": "have been introduced to",
    "object": "classify epileptic EEG signals",
    "sentence": "Neighbor Descriptive Pattern [LNDP] and One-dimensional Local Gradient Pattern [1D-LGP]) have been introduced to classify epileptic EEG signals.",
    "id": "00519"
  },
  {
    "subject": "The classification",
    "predicate": "is performed using",
    "object": "different machine learning classifiers",
    "sentence": "The classification between epileptic seizure and non -seizure signals is performed using different machine learning classifiers.",
    "id": "00519"
  },
  {
    "subject": "The benchmark epilepsy EEG dataset",
    "predicate": "provided by",
    "object": "the University of Bonn",
    "sentence": "The benchmark epilepsy EEG dataset provided by the University of Bonn is used in this research.",
    "id": "00519"
  },
  {
    "subject": "The benchmark epilepsy EEG dataset",
    "predicate": "used in",
    "object": "this research",
    "sentence": "The benchmark epilepsy EEG dataset provided by the University of Bonn is used in this research.",
    "id": "00519"
  },
  {
    "subject": "The classification performance",
    "predicate": "is evaluated using",
    "object": "10 -fold cross validation",
    "sentence": "The classification performance is evaluated using 10 -fold cross validation.",
    "id": "00519"
  },
  {
    "subject": "The classifiers",
    "predicate": "are",
    "object": "the Nearest Neighbor (NN), Support Vector Machine (SVM), Decision Tree (DT) and Artificial Neural Network (ANN)",
    "sentence": "The classifiers used are the Nearest Neighbor (NN), Support Vector Machine (SVM), Decision Tree (DT) and Artificial Neural Network (ANN).",
    "id": "00519"
  },
  {
    "subject": "The experiments",
    "predicate": "have been repeated",
    "object": "50 times",
    "sentence": "The experiments have been repeated for 50 times.",
    "id": "00519"
  },
  {
    "subject": "LNDP and 1D-LGP feature extraction techniques with ANN classifier",
    "predicate": "achieved",
    "object": "the average classification accuracy of 99.82% and 99.80%",
    "sentence": "Results: LNDP and 1D-LGP feature extraction techniques with ANN classifier achieved the average classification accuracy of 99.82% and 99.80%, respectively, for the classification between normal and epileptic EEG signals.",
    "id": "00519"
  },
  {
    "subject": "LNDP and 1D-LGP feature extraction techniques with ANN classifier",
    "predicate": "used for",
    "object": "the classification between normal and epileptic EEG signals",
    "sentence": "Results: LNDP and 1D-LGP feature extraction techniques with ANN classifier achieved the average classification accuracy of 99.82% and 99.80%, respectively, for the classification between normal and epileptic EEG signals.",
    "id": "00519"
  },
  {
    "subject": "Eight different experimental cases",
    "predicate": "were",
    "object": "tested",
    "sentence": "Eight different experimental cases were tested.",
    "id": "00519"
  },
  {
    "subject": "The classification results",
    "predicate": "were better than",
    "object": "those of some existing methods",
    "sentence": "The classification results were better than those of some existing methods.",
    "id": "00519"
  },
  {
    "subject": "This study",
    "predicate": "suggests",
    "object": "LNDP and 1D-LGP could be effective feature extraction techniques for the classification of epileptic EEG signals.",
    "sentence": "Conclusions: This study suggests that LNDP and 1D-LGP could be effective feature extraction techniques for the classification of epileptic EEG signals.",
    "id": "00519"
  },
  {
    "subject": "Computer networks",
    "predicate": "consist of",
    "object": "assets such as hardware, software, and data sources",
    "sentence": " Computer networks consist of several assets such as hardware, software, and data sources.",
    "id": "00836"
  },
  {
    "subject": "These assets",
    "predicate": "have",
    "object": "some vulnerabilities",
    "sentence": "These assets have often some vulnerabilities which can be exploited by attackers that violate security policies in the network.",
    "id": "00836"
  },
  {
    "subject": "vulnerabilities",
    "predicate": "can be exploited by",
    "object": "attackers",
    "sentence": "These assets have often some vulnerabilities which can be exploited by attackers that violate security policies in the network.",
    "id": "00836"
  },
  {
    "subject": "attackers",
    "predicate": "violate",
    "object": "security policies in the network",
    "sentence": "These assets have often some vulnerabilities which can be exploited by attackers that violate security policies in the network.",
    "id": "00836"
  },
  {
    "subject": "the network administrator",
    "predicate": "should analyze and prioritize",
    "object": "these vulnerabilities",
    "sentence": "Considering the limited budget, the network administrator should analyze and prioritize these vulnerabilities to be able to efficiently protect a network by mitigating the most risky ones.",
    "id": "00836"
  },
  {
    "subject": "the network administrator",
    "predicate": "protect",
    "object": "a network",
    "sentence": "Considering the limited budget, the network administrator should analyze and prioritize these vulnerabilities to be able to efficiently protect a network by mitigating the most risky ones.",
    "id": "00836"
  },
  {
    "subject": "the network administrator",
    "predicate": "mitigate",
    "object": "the most risky ones",
    "sentence": "Considering the limited budget, the network administrator should analyze and prioritize these vulnerabilities to be able to efficiently protect a network by mitigating the most risky ones.",
    "id": "00836"
  },
  {
    "subject": "several security parameters",
    "predicate": "are offered to",
    "object": "analyze security risks",
    "sentence": "So far, several security parameters are offered to analyze security risks from the network security administrator's perspective.",
    "id": "00836"
  },
  {
    "subject": "network security administrator",
    "predicate": "analyze",
    "object": "security risks",
    "sentence": "So far, several security parameters are offered to analyze security risks from the network security administrator's perspective.",
    "id": "00836"
  },
  {
    "subject": "these methods",
    "predicate": "do not consider",
    "object": "attacker's motivation",
    "sentence": "The major drawback of these methods is that they do not consider attacker's motivation.",
    "id": "00836"
  },
  {
    "subject": "motivation of potential attackers",
    "predicate": "influence",
    "object": "selection of different attack path",
    "sentence": "Depending on the motivation of potential attackers, different attack path may be selected for network security compromise.",
    "id": "00836"
  },
  {
    "subject": "different attack path",
    "predicate": "may be selected for",
    "object": "network security compromise",
    "sentence": "Depending on the motivation of potential attackers, different attack path may be selected for network security compromise.",
    "id": "00836"
  },
  {
    "subject": "attacker's motivation",
    "predicate": "is",
    "object": "a key factor in predicting the attacker's behavior",
    "sentence": "So, attacker's motivation is a key factor in predicting the attacker's behavior.",
    "id": "00836"
  },
  {
    "subject": "attacker's motivation",
    "predicate": "is considered in",
    "object": "the process of security risk analysis",
    "sentence": "In this paper, the attacker's motivation is considered in the process of security risk analysis, so network administrators are able to analyze security risks more accurately.",
    "id": "00836"
  },
  {
    "subject": "network administrators",
    "predicate": "are able to analyze",
    "object": "security risks more accurately",
    "sentence": "In this paper, the attacker's motivation is considered in the process of security risk analysis, so network administrators are able to analyze security risks more accurately.",
    "id": "00836"
  },
  {
    "subject": "The proposed method",
    "predicate": "is applied on",
    "object": "a network",
    "sentence": "The proposed method is applied on a network and the results are compared with novel works in this area.",
    "id": "00836"
  },
  {
    "subject": "The results",
    "predicate": "are compared with",
    "object": "novel works in this area",
    "sentence": "The proposed method is applied on a network and the results are compared with novel works in this area.",
    "id": "00836"
  },
  {
    "subject": "network administrator",
    "predicate": "predict",
    "object": "the behavior of attackers",
    "sentence": "The experimental results show that network administrator will be able to precisely predict the behavior of attackers and apply countermeasures more efficiently.",
    "id": "00836"
  },
  {
    "subject": "network administrator",
    "predicate": "apply",
    "object": "countermeasures",
    "sentence": "The experimental results show that network administrator will be able to precisely predict the behavior of attackers and apply countermeasures more efficiently.",
    "id": "00836"
  },
  {
    "subject": "Data sharing and information exchange",
    "predicate": "is a requirement for",
    "object": "convenient and effective data availability",
    "sentence": " Data sharing and information exchange among medical institutions is a requirement for convenient and effective data availability for both healthcare professionals and patients.",
    "id": "01046"
  },
  {
    "subject": "convenient and effective data availability",
    "predicate": "is for",
    "object": "healthcare professionals and patients",
    "sentence": " Data sharing and information exchange among medical institutions is a requirement for convenient and effective data availability for both healthcare professionals and patients.",
    "id": "01046"
  },
  {
    "subject": "characteristics of medical data",
    "predicate": "are",
    "object": "studied",
    "sentence": "In this paper, the characteristics of medical data are studied; two mainstream technologies of data storage for medical information are compared, and three strategies of medical documents storage are described with detailed advantages and disadvantages.",
    "id": "01046"
  },
  {
    "subject": "two mainstream technologies of data storage for medical information",
    "predicate": "are",
    "object": "compared",
    "sentence": "In this paper, the characteristics of medical data are studied; two mainstream technologies of data storage for medical information are compared, and three strategies of medical documents storage are described with detailed advantages and disadvantages.",
    "id": "01046"
  },
  {
    "subject": "three strategies of medical documents storage",
    "predicate": "are",
    "object": "described",
    "sentence": "In this paper, the characteristics of medical data are studied; two mainstream technologies of data storage for medical information are compared, and three strategies of medical documents storage are described with detailed advantages and disadvantages.",
    "id": "01046"
  },
  {
    "subject": "Semi-structured storage technology",
    "predicate": "is",
    "object": "easier to deploy",
    "sentence": "Semi-structured storage technology is easier to deploy and much more promising to promote in a wider range than all-structured methods.",
    "id": "01046"
  },
  {
    "subject": "Semi-structured storage technology",
    "predicate": "is",
    "object": "more promising to promote in a wider range",
    "sentence": "Semi-structured storage technology is easier to deploy and much more promising to promote in a wider range than all-structured methods.",
    "id": "01046"
  },
  {
    "subject": "Semi-structured storage technology",
    "predicate": "is",
    "object": "more promising than all-structured methods",
    "sentence": "Semi-structured storage technology is easier to deploy and much more promising to promote in a wider range than all-structured methods.",
    "id": "01046"
  },
  {
    "subject": "The combination of central and distributed data storage",
    "predicate": "is",
    "object": "more practical for regional data sharing",
    "sentence": "The combination of central and distributed data storage is more practical for regional data sharing.",
    "id": "01046"
  },
  {
    "subject": "This analysis",
    "predicate": "suggests",
    "object": "semi-structural data storage technology and the combination of central and distributed data storage are efficient and fit well the current situation in China",
    "sentence": "This analysis suggests that semi-structural data storage technology and the combination of central and distributed data storage are efficient and fit well the current situation in China.",
    "id": "01046"
  },
  {
    "subject": "Data Structures and Algorithms",
    "predicate": "are a part of",
    "object": "Computer Science",
    "sentence": " Data Structures and Algorithms are a central part of Computer Science.",
    "id": "01049"
  },
  {
    "subject": "their abstract and dynamic nature",
    "predicate": "make",
    "object": "a difficult topic to learn for many students",
    "sentence": "Due to their abstract and dynamic nature, they are a difficult topic to learn for many students.",
    "id": "01049"
  },
  {
    "subject": "instructors",
    "predicate": "have turned to",
    "object": "algorithm visualizations (AV) and AV systems",
    "sentence": "To alleviate these learning difficulties, instructors have turned to algorithm visualizations (AV) and AV systems.",
    "id": "01049"
  },
  {
    "subject": "engaging AVs",
    "predicate": "can have an impact on",
    "object": "student learning of DSA topics",
    "sentence": "Research has shown that especially engaging AVs can have an impact on student learning of DSA topics.",
    "id": "01049"
  },
  {
    "subject": "most AV systems",
    "predicate": "were",
    "object": "Java-based systems",
    "sentence": "Until recently, most AV systems were Java-based systems.",
    "id": "01049"
  },
  {
    "subject": "popularity of Java",
    "predicate": "has declined",
    "object": "",
    "sentence": "But, the popularity of Java has declined and is being supplanted by HTML5 and JavaScript content online.",
    "id": "01049"
  },
  {
    "subject": "HTML5 and JavaScript content online",
    "predicate": "is supplanting",
    "object": "popularity of Java",
    "sentence": "But, the popularity of Java has declined and is being supplanted by HTML5 and JavaScript content online.",
    "id": "01049"
  },
  {
    "subject": "we",
    "predicate": "present",
    "object": "JSAV: the JavaScript AV development library",
    "sentence": "In this paper, we present JSAV: the JavaScript AV development library.",
    "id": "01049"
  },
  {
    "subject": "JSAV",
    "predicate": "goes beyond",
    "object": "traditional AV library support for displaying standard data structures components",
    "sentence": "JSAV goes beyond traditional AV library support for displaying standard data structures components, to provide functionality to simplify creation of AVs on many engagement levels including interactive exercises.",
    "id": "01049"
  },
  {
    "subject": "JSAV",
    "predicate": "provide",
    "object": "functionality to simplify creation of AVs on many engagement levels including interactive exercises",
    "sentence": "JSAV goes beyond traditional AV library support for displaying standard data structures components, to provide functionality to simplify creation of AVs on many engagement levels including interactive exercises.",
    "id": "01049"
  },
  {
    "subject": "We",
    "predicate": "describe",
    "object": "the growing body of content created with JSAV",
    "sentence": "We describe the growing body of content created with JSAV and summarize our three years of experience and research results from using JSAV to build content that supports CS education.",
    "id": "01049"
  },
  {
    "subject": "We",
    "predicate": "summarize",
    "object": "our three years of experience and research results from using JSAV",
    "sentence": "We describe the growing body of content created with JSAV and summarize our three years of experience and research results from using JSAV to build content that supports CS education.",
    "id": "01049"
  },
  {
    "subject": "JSAV",
    "predicate": "used to",
    "object": "build content that supports CS education",
    "sentence": "We describe the growing body of content created with JSAV and summarize our three years of experience and research results from using JSAV to build content that supports CS education.",
    "id": "01049"
  },
  {
    "subject": "Extracting OWL ontologies from relational databases",
    "predicate": "is",
    "object": "extremely helpful for realising the Semantic Web vision",
    "sentence": " Extracting OWL ontologies from relational databases is extremely helpful for realising the Semantic Web vision.",
    "id": "01370"
  },
  {
    "subject": "most of the approaches",
    "predicate": "drop",
    "object": "many of the expressive features of OWL",
    "sentence": "However, most of the approaches in this context often drop many of the expressive features of OWL.",
    "id": "01370"
  },
  {
    "subject": "highly expressive axioms",
    "predicate": "can not be detected from",
    "object": "database schema alone",
    "sentence": "This is because highly expressive axioms can not be detected from database schema alone, but instead require a combined analysis of the database schema and data.",
    "id": "01370"
  },
  {
    "subject": "highly expressive axioms",
    "predicate": "require",
    "object": "a combined analysis of the database schema and data",
    "sentence": "This is because highly expressive axioms can not be detected from database schema alone, but instead require a combined analysis of the database schema and data.",
    "id": "01370"
  },
  {
    "subject": "we",
    "predicate": "present",
    "object": "an approach",
    "sentence": "In this paper, we present an approach that transforms a relational schema to a basic OWL schema, and then enhances it with rich OWL 2 constructs using schema and data analysis techniques.",
    "id": "01370"
  },
  {
    "subject": "an approach",
    "predicate": "transforms",
    "object": "a relational schema to a basic OWL schema",
    "sentence": "In this paper, we present an approach that transforms a relational schema to a basic OWL schema, and then enhances it with rich OWL 2 constructs using schema and data analysis techniques.",
    "id": "01370"
  },
  {
    "subject": "an approach",
    "predicate": "enhances",
    "object": "it with rich OWL 2 constructs using schema and data analysis techniques",
    "sentence": "In this paper, we present an approach that transforms a relational schema to a basic OWL schema, and then enhances it with rich OWL 2 constructs using schema and data analysis techniques.",
    "id": "01370"
  },
  {
    "subject": "We",
    "predicate": "rely on",
    "object": "the user for the verification of these features",
    "sentence": "We then rely on the user for the verification of these features.",
    "id": "01370"
  },
  {
    "subject": "we",
    "predicate": "apply",
    "object": "machine learning algorithms",
    "sentence": "Furthermore, we apply machine learning algorithms to help in ranking the resulting features based on user supplied relevance scores.",
    "id": "01370"
  },
  {
    "subject": "machine learning algorithms",
    "predicate": "help in",
    "object": "ranking the resulting features",
    "sentence": "Furthermore, we apply machine learning algorithms to help in ranking the resulting features based on user supplied relevance scores.",
    "id": "01370"
  },
  {
    "subject": "ranking",
    "predicate": "based on",
    "object": "user supplied relevance scores",
    "sentence": "Furthermore, we apply machine learning algorithms to help in ranking the resulting features based on user supplied relevance scores.",
    "id": "01370"
  },
  {
    "subject": "our tool",
    "predicate": "tested on",
    "object": "a number of databases",
    "sentence": "Testing our tool on a number of databases demonstrates that our proposed approach is feasible and effective.",
    "id": "01370"
  },
  {
    "subject": "our proposed approach",
    "predicate": "is",
    "object": "feasible and effective",
    "sentence": "Testing our tool on a number of databases demonstrates that our proposed approach is feasible and effective.",
    "id": "01370"
  },
  {
    "subject": "Formal language theory",
    "predicate": "plays",
    "object": "a fundamental role in computer science",
    "sentence": " Formal language theory plays, in computer science, a fundamental role that allows, among other things, the development of one of the cornerstones of information technology: programming languages.",
    "id": "01466"
  },
  {
    "subject": "Formal language theory",
    "predicate": "allows",
    "object": "the development of programming languages",
    "sentence": " Formal language theory plays, in computer science, a fundamental role that allows, among other things, the development of one of the cornerstones of information technology: programming languages.",
    "id": "01466"
  },
  {
    "subject": "They",
    "predicate": "define",
    "object": "the mandatory grammatical rules",
    "sentence": "They define the mandatory grammatical rules that programmers need to follow to create the tools that enable humans to interact with machines.",
    "id": "01466"
  },
  {
    "subject": "programmers",
    "predicate": "need to follow",
    "object": "the mandatory grammatical rules",
    "sentence": "They define the mandatory grammatical rules that programmers need to follow to create the tools that enable humans to interact with machines.",
    "id": "01466"
  },
  {
    "subject": "programmers",
    "predicate": "create",
    "object": "the tools",
    "sentence": "They define the mandatory grammatical rules that programmers need to follow to create the tools that enable humans to interact with machines.",
    "id": "01466"
  },
  {
    "subject": "the tools",
    "predicate": "enable",
    "object": "humans to interact with machines",
    "sentence": "They define the mandatory grammatical rules that programmers need to follow to create the tools that enable humans to interact with machines.",
    "id": "01466"
  },
  {
    "subject": "formal language theory",
    "predicate": "is often taken for granted by",
    "object": "software developers",
    "sentence": "Despite its significance, formal language theory is often taken for granted, even by software developers, who regularly follow the rules of their programming domain.",
    "id": "01466"
  },
  {
    "subject": "software developers",
    "predicate": "follow",
    "object": "the rules of their programming domain",
    "sentence": "Despite its significance, formal language theory is often taken for granted, even by software developers, who regularly follow the rules of their programming domain.",
    "id": "01466"
  },
  {
    "subject": "the developer",
    "predicate": "is creating",
    "object": "its own programming language",
    "sentence": "Unless the developer is creating its own programming language, data structure, or describing the formal background of an existing one, he will not need to dive deep into formal languages, grammar or automaton theory.",
    "id": "01466"
  },
  {
    "subject": "the developer",
    "predicate": "is creating",
    "object": "data structure",
    "sentence": "Unless the developer is creating its own programming language, data structure, or describing the formal background of an existing one, he will not need to dive deep into formal languages, grammar or automaton theory.",
    "id": "01466"
  },
  {
    "subject": "the developer",
    "predicate": "is describing",
    "object": "the formal background of an existing one",
    "sentence": "Unless the developer is creating its own programming language, data structure, or describing the formal background of an existing one, he will not need to dive deep into formal languages, grammar or automaton theory.",
    "id": "01466"
  },
  {
    "subject": "he",
    "predicate": "will not need to dive deep into",
    "object": "formal languages",
    "sentence": "Unless the developer is creating its own programming language, data structure, or describing the formal background of an existing one, he will not need to dive deep into formal languages, grammar or automaton theory.",
    "id": "01466"
  },
  {
    "subject": "he",
    "predicate": "will not need to dive deep into",
    "object": "grammar",
    "sentence": "Unless the developer is creating its own programming language, data structure, or describing the formal background of an existing one, he will not need to dive deep into formal languages, grammar or automaton theory.",
    "id": "01466"
  },
  {
    "subject": "he",
    "predicate": "will not need to dive deep into",
    "object": "automaton theory",
    "sentence": "Unless the developer is creating its own programming language, data structure, or describing the formal background of an existing one, he will not need to dive deep into formal languages, grammar or automaton theory.",
    "id": "01466"
  },
  {
    "subject": "Those who do need to develop their own rules",
    "predicate": "have to understand",
    "object": "the theory of formal languages",
    "sentence": "Those who do need to develop their own rules will first have to understand the theory of formal languages, and the limitations they impose.",
    "id": "01466"
  },
  {
    "subject": "the theory of formal languages",
    "predicate": "impose",
    "object": "limitations",
    "sentence": "Those who do need to develop their own rules will first have to understand the theory of formal languages, and the limitations they impose.",
    "id": "01466"
  },
  {
    "subject": "This paper",
    "predicate": "do an introduction to",
    "object": "the fundamentals of language theory",
    "sentence": "This paper will do an introduction to the fundamentals of language theory, their classification, restrictions and representation.",
    "id": "01466"
  },
  {
    "subject": "the fundamentals of language theory",
    "predicate": "have",
    "object": "classification",
    "sentence": "This paper will do an introduction to the fundamentals of language theory, their classification, restrictions and representation.",
    "id": "01466"
  },
  {
    "subject": "the fundamentals of language theory",
    "predicate": "have",
    "object": "restrictions",
    "sentence": "This paper will do an introduction to the fundamentals of language theory, their classification, restrictions and representation.",
    "id": "01466"
  },
  {
    "subject": "the fundamentals of language theory",
    "predicate": "have",
    "object": "representation",
    "sentence": "This paper will do an introduction to the fundamentals of language theory, their classification, restrictions and representation.",
    "id": "01466"
  },
  {
    "subject": "we",
    "predicate": "use",
    "object": "worldwide known data structure format such as the JavaScript Object Notation (JSON)",
    "sentence": "Once this ground rules are set, we will use a worldwide known data structure format such as the JavaScript Object Notation (JSON), to formally define its grammar rules and automaton.",
    "id": "01466"
  },
  {
    "subject": "we",
    "predicate": "define",
    "object": "its grammar rules and automaton",
    "sentence": "Once this ground rules are set, we will use a worldwide known data structure format such as the JavaScript Object Notation (JSON), to formally define its grammar rules and automaton.",
    "id": "01466"
  },
  {
    "subject": "this formal background",
    "predicate": "allow",
    "object": "us to transform theory into bits",
    "sentence": "All of this formal background will allow us to transform theory into bits, by developing an algorithm that will analyze streams of texts, accepting or rejecting them as they comply or not with the predefined rules.",
    "id": "01466"
  },
  {
    "subject": "an algorithm",
    "predicate": "analyze",
    "object": "streams of texts",
    "sentence": "All of this formal background will allow us to transform theory into bits, by developing an algorithm that will analyze streams of texts, accepting or rejecting them as they comply or not with the predefined rules.",
    "id": "01466"
  },
  {
    "subject": "streams of texts",
    "predicate": "comply or not",
    "object": "with the predefined rules",
    "sentence": "All of this formal background will allow us to transform theory into bits, by developing an algorithm that will analyze streams of texts, accepting or rejecting them as they comply or not with the predefined rules.",
    "id": "01466"
  },
  {
    "subject": "we",
    "predicate": "analyze",
    "object": "the outcomes of this implementation",
    "sentence": "Finally, we will analyze the outcomes of this implementation, its benefits, limitations, and alternatives that could have been followed.",
    "id": "01466"
  },
  {
    "subject": "we",
    "predicate": "analyze",
    "object": "its benefits",
    "sentence": "Finally, we will analyze the outcomes of this implementation, its benefits, limitations, and alternatives that could have been followed.",
    "id": "01466"
  },
  {
    "subject": "we",
    "predicate": "analyze",
    "object": "limitations",
    "sentence": "Finally, we will analyze the outcomes of this implementation, its benefits, limitations, and alternatives that could have been followed.",
    "id": "01466"
  },
  {
    "subject": "we",
    "predicate": "analyze",
    "object": "alternatives that could have been followed",
    "sentence": "Finally, we will analyze the outcomes of this implementation, its benefits, limitations, and alternatives that could have been followed.",
    "id": "01466"
  },
  {
    "subject": "we",
    "predicate": "have seen",
    "object": "an amazing development of image processing techniques targeted for medical applications",
    "sentence": " In the last two decades, we have seen an amazing development of image processing techniques targeted for medical applications.",
    "id": "01925"
  },
  {
    "subject": "We",
    "predicate": "propose",
    "object": "multi-GPU-based parallel real-time algorithms for segmentation and shape-based object detection",
    "sentence": "We propose multi-GPU-based parallel real-time algorithms for segmentation and shape-based object detection, aiming at accelerating two medical image processing methods: automated blood detection in wireless capsule endoscopy (WCE) images and automated bright lesion detection in retinal fundus images.",
    "id": "01925"
  },
  {
    "subject": "multi-GPU-based parallel real-time algorithms",
    "predicate": "aiming at",
    "object": "accelerating two medical image processing methods",
    "sentence": "We propose multi-GPU-based parallel real-time algorithms for segmentation and shape-based object detection, aiming at accelerating two medical image processing methods: automated blood detection in wireless capsule endoscopy (WCE) images and automated bright lesion detection in retinal fundus images.",
    "id": "01925"
  },
  {
    "subject": "two medical image processing methods",
    "predicate": "include",
    "object": "automated blood detection in wireless capsule endoscopy (WCE) images",
    "sentence": "We propose multi-GPU-based parallel real-time algorithms for segmentation and shape-based object detection, aiming at accelerating two medical image processing methods: automated blood detection in wireless capsule endoscopy (WCE) images and automated bright lesion detection in retinal fundus images.",
    "id": "01925"
  },
  {
    "subject": "two medical image processing methods",
    "predicate": "include",
    "object": "automated bright lesion detection in retinal fundus images",
    "sentence": "We propose multi-GPU-based parallel real-time algorithms for segmentation and shape-based object detection, aiming at accelerating two medical image processing methods: automated blood detection in wireless capsule endoscopy (WCE) images and automated bright lesion detection in retinal fundus images.",
    "id": "01925"
  },
  {
    "subject": "segmentation and object detection",
    "predicate": "identified as",
    "object": "responsible for consuming most of the global processing time",
    "sentence": "In the former method we identified segmentation and object detection as being responsible for consuming most of the global processing time.",
    "id": "01925"
  },
  {
    "subject": "shape-based object detection",
    "predicate": "was",
    "object": "the compute-intensive task identified",
    "sentence": "While in the latter, as segmentation was not used, shape-based object detection was the compute-intensive task identified.",
    "id": "01925"
  },
  {
    "subject": "the accelerated method",
    "predicate": "running on",
    "object": "multi-GPU systems for blood detection in WCE images",
    "sentence": "Experimental results show that the accelerated method running on multi-GPU systems for blood detection in WCE images is on average 265 times faster than the original CPU version and is able to process 344 frames per second.",
    "id": "01925"
  },
  {
    "subject": "the accelerated method",
    "predicate": "is",
    "object": "on average 265 times faster than the original CPU version",
    "sentence": "Experimental results show that the accelerated method running on multi-GPU systems for blood detection in WCE images is on average 265 times faster than the original CPU version and is able to process 344 frames per second.",
    "id": "01925"
  },
  {
    "subject": "the accelerated method",
    "predicate": "is able to process",
    "object": "344 frames per second",
    "sentence": "Experimental results show that the accelerated method running on multi-GPU systems for blood detection in WCE images is on average 265 times faster than the original CPU version and is able to process 344 frames per second.",
    "id": "01925"
  },
  {
    "subject": "we",
    "predicate": "applying",
    "object": "the multi-GPU framework for bright lesion detection in fundus images",
    "sentence": "By applying the multi-GPU framework for bright lesion detection in fundus images we are able to process 62 frames per second with a speedup average 667 times faster than the equivalent CPU version.",
    "id": "01925"
  },
  {
    "subject": "we",
    "predicate": "are able to process",
    "object": "62 frames per second",
    "sentence": "By applying the multi-GPU framework for bright lesion detection in fundus images we are able to process 62 frames per second with a speedup average 667 times faster than the equivalent CPU version.",
    "id": "01925"
  },
  {
    "subject": "speedup average",
    "predicate": "is",
    "object": "667 times faster than the equivalent CPU version",
    "sentence": "By applying the multi-GPU framework for bright lesion detection in fundus images we are able to process 62 frames per second with a speedup average 667 times faster than the equivalent CPU version.",
    "id": "01925"
  },
  {
    "subject": "we",
    "predicate": "focus on",
    "object": "gender classification from face images",
    "sentence": " In this paper we focus on gender classification from face images.",
    "id": "02026"
  },
  {
    "subject": "advances in equipment as well as methods",
    "predicate": "used for",
    "object": "automatic face image processing for recognition or extraction of demographics",
    "sentence": "Despite advances in equipment as well as methods, automatic face image processing for recognition or even just for the extraction of demographics, is still a challenging task in unrestricted scenarios.",
    "id": "02026"
  },
  {
    "subject": "automatic face image processing for recognition or extraction of demographics",
    "predicate": "is",
    "object": "a challenging task in unrestricted scenarios",
    "sentence": "Despite advances in equipment as well as methods, automatic face image processing for recognition or even just for the extraction of demographics, is still a challenging task in unrestricted scenarios.",
    "id": "02026"
  },
  {
    "subject": "Our tests",
    "predicate": "are aimed at",
    "object": "carrying out an extensive comparison of a feature based approach with two score based ones",
    "sentence": "Our tests are aimed at carrying out an extensive comparison of a feature based approach with two score based ones.",
    "id": "02026"
  },
  {
    "subject": "we",
    "predicate": "apply",
    "object": "different operators",
    "sentence": "When directly using features, we first apply different operators to extract the corresponding feature vectors, and then stack such vectors.",
    "id": "02026"
  },
  {
    "subject": "different operators",
    "predicate": "extract",
    "object": "the corresponding feature vectors",
    "sentence": "When directly using features, we first apply different operators to extract the corresponding feature vectors, and then stack such vectors.",
    "id": "02026"
  },
  {
    "subject": "we",
    "predicate": "stack",
    "object": "such vectors",
    "sentence": "When directly using features, we first apply different operators to extract the corresponding feature vectors, and then stack such vectors.",
    "id": "02026"
  },
  {
    "subject": "These",
    "predicate": "are classified by",
    "object": "a SVM-based approach",
    "sentence": "These are classified by a SVM-based approach.",
    "id": "02026"
  },
  {
    "subject": "different operators",
    "predicate": "are applied",
    "object": "in a completely separate way",
    "sentence": "When using scores, the different operators are applied in a completely separate way, so that each of them produces the corresponding scores.",
    "id": "02026"
  },
  {
    "subject": "each of them",
    "predicate": "produces",
    "object": "the corresponding scores",
    "sentence": "When using scores, the different operators are applied in a completely separate way, so that each of them produces the corresponding scores.",
    "id": "02026"
  },
  {
    "subject": "Answers",
    "predicate": "fed to",
    "object": "a SVM",
    "sentence": "Answers are then either fed to a SVM, or compared pairwise to exploit Likelihood Ratio.",
    "id": "02026"
  },
  {
    "subject": "Answers",
    "predicate": "compared pairwise to exploit",
    "object": "Likelihood Ratio",
    "sentence": "Answers are then either fed to a SVM, or compared pairwise to exploit Likelihood Ratio.",
    "id": "02026"
  },
  {
    "subject": "The testbeds",
    "predicate": "used for",
    "object": "experiments",
    "sentence": "The testbeds used for experiments are EGA database, which presents a good balance with respect to demographic features of stored face images, and GROPUS, an increasingly popular benchmark for massive experiments.",
    "id": "02026"
  },
  {
    "subject": "EGA database",
    "predicate": "presents",
    "object": "a good balance with respect to demographic features of stored face images",
    "sentence": "The testbeds used for experiments are EGA database, which presents a good balance with respect to demographic features of stored face images, and GROPUS, an increasingly popular benchmark for massive experiments.",
    "id": "02026"
  },
  {
    "subject": "GROPUS",
    "predicate": "is",
    "object": "an increasingly popular benchmark for massive experiments",
    "sentence": "The testbeds used for experiments are EGA database, which presents a good balance with respect to demographic features of stored face images, and GROPUS, an increasingly popular benchmark for massive experiments.",
    "id": "02026"
  },
  {
    "subject": "The obtained performances",
    "predicate": "confirm",
    "object": "feature level fusion achieves an often better classification accuracy",
    "sentence": "The obtained performances confirm that feature level fusion achieves an often better classification accuracy.",
    "id": "02026"
  },
  {
    "subject": "it",
    "predicate": "is",
    "object": "computationally expensive",
    "sentence": "However, it is computationally expensive.",
    "id": "02026"
  },
  {
    "subject": "we",
    "predicate": "contribute to",
    "object": "the research on this topic",
    "sentence": "We contribute to the research on this topic in three ways: 1) we show that the proposed score level fusion approaches, though less demanding, can achieve results that are comparable to feature level fusion, or even slightly better given that we fuse a particular set of experts; the main advantage over the feature-based approach relying on chained vectors, is that it is not required to evaluate a complex multi-feature distribution and the training process: thanks to the individual training of experts the overall process is more efficient and flexible, since experts can be easily added or discarded from the final architecture; 2) we evaluate the number of uncertain/ambiguous cases, i.e., those that might cause classification errors depending on the classification thresholds used, and show that with our score level fusion these significantly decreases; despite the final rate of correct classifications, this results in a more robust system; 3) we achieve very good results with operators that are not computationally expensive.",
    "id": "02026"
  },
  {
    "subject": "the proposed score level fusion approaches",
    "predicate": "can achieve",
    "object": "results that are comparable to feature level fusion",
    "sentence": "We contribute to the research on this topic in three ways: 1) we show that the proposed score level fusion approaches, though less demanding, can achieve results that are comparable to feature level fusion, or even slightly better given that we fuse a particular set of experts; the main advantage over the feature-based approach relying on chained vectors, is that it is not required to evaluate a complex multi-feature distribution and the training process: thanks to the individual training of experts the overall process is more efficient and flexible, since experts can be easily added or discarded from the final architecture; 2) we evaluate the number of uncertain/ambiguous cases, i.e., those that might cause classification errors depending on the classification thresholds used, and show that with our score level fusion these significantly decreases; despite the final rate of correct classifications, this results in a more robust system; 3) we achieve very good results with operators that are not computationally expensive.",
    "id": "02026"
  },
  {
    "subject": "the proposed score level fusion approaches",
    "predicate": "are",
    "object": "less demanding",
    "sentence": "We contribute to the research on this topic in three ways: 1) we show that the proposed score level fusion approaches, though less demanding, can achieve results that are comparable to feature level fusion, or even slightly better given that we fuse a particular set of experts; the main advantage over the feature-based approach relying on chained vectors, is that it is not required to evaluate a complex multi-feature distribution and the training process: thanks to the individual training of experts the overall process is more efficient and flexible, since experts can be easily added or discarded from the final architecture; 2) we evaluate the number of uncertain/ambiguous cases, i.e., those that might cause classification errors depending on the classification thresholds used, and show that with our score level fusion these significantly decreases; despite the final rate of correct classifications, this results in a more robust system; 3) we achieve very good results with operators that are not computationally expensive.",
    "id": "02026"
  },
  {
    "subject": "we",
    "predicate": "fuse",
    "object": "a particular set of experts",
    "sentence": "We contribute to the research on this topic in three ways: 1) we show that the proposed score level fusion approaches, though less demanding, can achieve results that are comparable to feature level fusion, or even slightly better given that we fuse a particular set of experts; the main advantage over the feature-based approach relying on chained vectors, is that it is not required to evaluate a complex multi-feature distribution and the training process: thanks to the individual training of experts the overall process is more efficient and flexible, since experts can be easily added or discarded from the final architecture; 2) we evaluate the number of uncertain/ambiguous cases, i.e., those that might cause classification errors depending on the classification thresholds used, and show that with our score level fusion these significantly decreases; despite the final rate of correct classifications, this results in a more robust system; 3) we achieve very good results with operators that are not computationally expensive.",
    "id": "02026"
  },
  {
    "subject": "the feature-based approach relying on chained vectors",
    "predicate": "is not required to",
    "object": "evaluate a complex multi-feature distribution and the training process",
    "sentence": "We contribute to the research on this topic in three ways: 1) we show that the proposed score level fusion approaches, though less demanding, can achieve results that are comparable to feature level fusion, or even slightly better given that we fuse a particular set of experts; the main advantage over the feature-based approach relying on chained vectors, is that it is not required to evaluate a complex multi-feature distribution and the training process: thanks to the individual training of experts the overall process is more efficient and flexible, since experts can be easily added or discarded from the final architecture; 2) we evaluate the number of uncertain/ambiguous cases, i.e., those that might cause classification errors depending on the classification thresholds used, and show that with our score level fusion these significantly decreases; despite the final rate of correct classifications, this results in a more robust system; 3) we achieve very good results with operators that are not computationally expensive.",
    "id": "02026"
  },
  {
    "subject": "the overall process",
    "predicate": "is",
    "object": "more efficient and flexible",
    "sentence": "We contribute to the research on this topic in three ways: 1) we show that the proposed score level fusion approaches, though less demanding, can achieve results that are comparable to feature level fusion, or even slightly better given that we fuse a particular set of experts; the main advantage over the feature-based approach relying on chained vectors, is that it is not required to evaluate a complex multi-feature distribution and the training process: thanks to the individual training of experts the overall process is more efficient and flexible, since experts can be easily added or discarded from the final architecture; 2) we evaluate the number of uncertain/ambiguous cases, i.e., those that might cause classification errors depending on the classification thresholds used, and show that with our score level fusion these significantly decreases; despite the final rate of correct classifications, this results in a more robust system; 3) we achieve very good results with operators that are not computationally expensive.",
    "id": "02026"
  },
  {
    "subject": "experts",
    "predicate": "can be",
    "object": "easily added or discarded from the final architecture",
    "sentence": "We contribute to the research on this topic in three ways: 1) we show that the proposed score level fusion approaches, though less demanding, can achieve results that are comparable to feature level fusion, or even slightly better given that we fuse a particular set of experts; the main advantage over the feature-based approach relying on chained vectors, is that it is not required to evaluate a complex multi-feature distribution and the training process: thanks to the individual training of experts the overall process is more efficient and flexible, since experts can be easily added or discarded from the final architecture; 2) we evaluate the number of uncertain/ambiguous cases, i.e., those that might cause classification errors depending on the classification thresholds used, and show that with our score level fusion these significantly decreases; despite the final rate of correct classifications, this results in a more robust system; 3) we achieve very good results with operators that are not computationally expensive.",
    "id": "02026"
  },
  {
    "subject": "we",
    "predicate": "evaluate",
    "object": "the number of uncertain/ambiguous cases",
    "sentence": "We contribute to the research on this topic in three ways: 1) we show that the proposed score level fusion approaches, though less demanding, can achieve results that are comparable to feature level fusion, or even slightly better given that we fuse a particular set of experts; the main advantage over the feature-based approach relying on chained vectors, is that it is not required to evaluate a complex multi-feature distribution and the training process: thanks to the individual training of experts the overall process is more efficient and flexible, since experts can be easily added or discarded from the final architecture; 2) we evaluate the number of uncertain/ambiguous cases, i.e., those that might cause classification errors depending on the classification thresholds used, and show that with our score level fusion these significantly decreases; despite the final rate of correct classifications, this results in a more robust system; 3) we achieve very good results with operators that are not computationally expensive.",
    "id": "02026"
  },
  {
    "subject": "uncertain/ambiguous cases",
    "predicate": "might cause",
    "object": "classification errors",
    "sentence": "We contribute to the research on this topic in three ways: 1) we show that the proposed score level fusion approaches, though less demanding, can achieve results that are comparable to feature level fusion, or even slightly better given that we fuse a particular set of experts; the main advantage over the feature-based approach relying on chained vectors, is that it is not required to evaluate a complex multi-feature distribution and the training process: thanks to the individual training of experts the overall process is more efficient and flexible, since experts can be easily added or discarded from the final architecture; 2) we evaluate the number of uncertain/ambiguous cases, i.e., those that might cause classification errors depending on the classification thresholds used, and show that with our score level fusion these significantly decreases; despite the final rate of correct classifications, this results in a more robust system; 3) we achieve very good results with operators that are not computationally expensive.",
    "id": "02026"
  },
  {
    "subject": "our score level fusion",
    "predicate": "significantly decreases",
    "object": "uncertain/ambiguous cases",
    "sentence": "We contribute to the research on this topic in three ways: 1) we show that the proposed score level fusion approaches, though less demanding, can achieve results that are comparable to feature level fusion, or even slightly better given that we fuse a particular set of experts; the main advantage over the feature-based approach relying on chained vectors, is that it is not required to evaluate a complex multi-feature distribution and the training process: thanks to the individual training of experts the overall process is more efficient and flexible, since experts can be easily added or discarded from the final architecture; 2) we evaluate the number of uncertain/ambiguous cases, i.e., those that might cause classification errors depending on the classification thresholds used, and show that with our score level fusion these significantly decreases; despite the final rate of correct classifications, this results in a more robust system; 3) we achieve very good results with operators that are not computationally expensive.",
    "id": "02026"
  },
  {
    "subject": "this",
    "predicate": "results in",
    "object": "a more robust system",
    "sentence": "We contribute to the research on this topic in three ways: 1) we show that the proposed score level fusion approaches, though less demanding, can achieve results that are comparable to feature level fusion, or even slightly better given that we fuse a particular set of experts; the main advantage over the feature-based approach relying on chained vectors, is that it is not required to evaluate a complex multi-feature distribution and the training process: thanks to the individual training of experts the overall process is more efficient and flexible, since experts can be easily added or discarded from the final architecture; 2) we evaluate the number of uncertain/ambiguous cases, i.e., those that might cause classification errors depending on the classification thresholds used, and show that with our score level fusion these significantly decreases; despite the final rate of correct classifications, this results in a more robust system; 3) we achieve very good results with operators that are not computationally expensive.",
    "id": "02026"
  },
  {
    "subject": "we",
    "predicate": "achieve",
    "object": "very good results with operators that are not computationally expensive",
    "sentence": "We contribute to the research on this topic in three ways: 1) we show that the proposed score level fusion approaches, though less demanding, can achieve results that are comparable to feature level fusion, or even slightly better given that we fuse a particular set of experts; the main advantage over the feature-based approach relying on chained vectors, is that it is not required to evaluate a complex multi-feature distribution and the training process: thanks to the individual training of experts the overall process is more efficient and flexible, since experts can be easily added or discarded from the final architecture; 2) we evaluate the number of uncertain/ambiguous cases, i.e., those that might cause classification errors depending on the classification thresholds used, and show that with our score level fusion these significantly decreases; despite the final rate of correct classifications, this results in a more robust system; 3) we achieve very good results with operators that are not computationally expensive.",
    "id": "02026"
  },
  {
    "subject": "Information sources such as relational databases, spreadsheets, XML, JSON, and Web APIs",
    "predicate": "contain",
    "object": "a tremendous amount of structured data",
    "sentence": " Information sources such as relational databases, spreadsheets, XML, JSON, and Web APIs contain a tremendous amount of structured data that can be leveraged to build and augment knowledge graphs.",
    "id": "02316"
  },
  {
    "subject": "a tremendous amount of structured data",
    "predicate": "can be leveraged to",
    "object": "build and augment knowledge graphs",
    "sentence": " Information sources such as relational databases, spreadsheets, XML, JSON, and Web APIs contain a tremendous amount of structured data that can be leveraged to build and augment knowledge graphs.",
    "id": "02316"
  },
  {
    "subject": "they",
    "predicate": "provide",
    "object": "a semantic model to describe their contents",
    "sentence": "However, they rarely provide a semantic model to describe their contents.",
    "id": "02316"
  },
  {
    "subject": "Semantic models of data sources",
    "predicate": "represent",
    "object": "the implicit meaning of the data",
    "sentence": "Semantic models of data sources represent the implicit meaning of the data by specifying the concepts and the relationships within the data.",
    "id": "02316"
  },
  {
    "subject": "Semantic models of data sources",
    "predicate": "specify",
    "object": "the concepts within the data",
    "sentence": "Semantic models of data sources represent the implicit meaning of the data by specifying the concepts and the relationships within the data.",
    "id": "02316"
  },
  {
    "subject": "Semantic models of data sources",
    "predicate": "specify",
    "object": "the relationships within the data",
    "sentence": "Semantic models of data sources represent the implicit meaning of the data by specifying the concepts and the relationships within the data.",
    "id": "02316"
  },
  {
    "subject": "Such models",
    "predicate": "are",
    "object": "the key ingredients to automatically publish the data into knowledge graphs",
    "sentence": "Such models are the key ingredients to automatically publish the data into knowledge graphs.",
    "id": "02316"
  },
  {
    "subject": "Manually modeling the semantics of data sources",
    "predicate": "requires",
    "object": "significant effort and expertise",
    "sentence": "Manually modeling the semantics of data sources requires significant effort and expertise, and although desirable, building these models automatically is a challenging problem.",
    "id": "02316"
  },
  {
    "subject": "building these models",
    "predicate": "is",
    "object": "a challenging problem",
    "sentence": "Manually modeling the semantics of data sources requires significant effort and expertise, and although desirable, building these models automatically is a challenging problem.",
    "id": "02316"
  },
  {
    "subject": "Most of the related work",
    "predicate": "focuses on",
    "object": "semantic annotation of the data fields",
    "sentence": "Most of the related work focuses on semantic annotation of the data fields (source attributes).",
    "id": "02316"
  },
  {
    "subject": "constructing a semantic model",
    "predicate": "describes",
    "object": "the relationships between the attributes",
    "sentence": "However, constructing a semantic model that explicitly describes the relationships between the attributes in addition to their semantic types is critical.",
    "id": "02316"
  },
  {
    "subject": "constructing a semantic model",
    "predicate": "describes",
    "object": "their semantic types",
    "sentence": "However, constructing a semantic model that explicitly describes the relationships between the attributes in addition to their semantic types is critical.",
    "id": "02316"
  },
  {
    "subject": "We",
    "predicate": "present",
    "object": "a novel approach",
    "sentence": "We present a novel approach that exploits the knowledge from a domain ontology and the semantic models of previously modeled sources to automatically learn a rich semantic model for a new source.",
    "id": "02316"
  },
  {
    "subject": "a novel approach",
    "predicate": "exploits",
    "object": "the knowledge from a domain ontology",
    "sentence": "We present a novel approach that exploits the knowledge from a domain ontology and the semantic models of previously modeled sources to automatically learn a rich semantic model for a new source.",
    "id": "02316"
  },
  {
    "subject": "a novel approach",
    "predicate": "exploits",
    "object": "the semantic models of previously modeled sources",
    "sentence": "We present a novel approach that exploits the knowledge from a domain ontology and the semantic models of previously modeled sources to automatically learn a rich semantic model for a new source.",
    "id": "02316"
  },
  {
    "subject": "a novel approach",
    "predicate": "learn",
    "object": "a rich semantic model for a new source",
    "sentence": "We present a novel approach that exploits the knowledge from a domain ontology and the semantic models of previously modeled sources to automatically learn a rich semantic model for a new source.",
    "id": "02316"
  },
  {
    "subject": "This model",
    "predicate": "represents",
    "object": "the semantics of the new source",
    "sentence": "This model represents the semantics of the new source in terms of the concepts and relationships defined by the domain ontology.",
    "id": "02316"
  },
  {
    "subject": "This model",
    "predicate": "defined by",
    "object": "the domain ontology",
    "sentence": "This model represents the semantics of the new source in terms of the concepts and relationships defined by the domain ontology.",
    "id": "02316"
  },
  {
    "subject": "we",
    "predicate": "leverage",
    "object": "the knowledge in the domain ontology and the known semantic models",
    "sentence": "Given some sample data from the new source, we leverage the knowledge in the domain ontology and the known semantic models to construct a weighted graph that represents the space of plausible semantic models for the new source.",
    "id": "02316"
  },
  {
    "subject": "we",
    "predicate": "construct",
    "object": "a weighted graph",
    "sentence": "Given some sample data from the new source, we leverage the knowledge in the domain ontology and the known semantic models to construct a weighted graph that represents the space of plausible semantic models for the new source.",
    "id": "02316"
  },
  {
    "subject": "weighted graph",
    "predicate": "represents",
    "object": "the space of plausible semantic models for the new source",
    "sentence": "Given some sample data from the new source, we leverage the knowledge in the domain ontology and the known semantic models to construct a weighted graph that represents the space of plausible semantic models for the new source.",
    "id": "02316"
  },
  {
    "subject": "we",
    "predicate": "compute",
    "object": "the top k candidate semantic models",
    "sentence": "Then, we compute the top k candidate semantic models and suggest to the user a ranked list of the semantic models for the new source.",
    "id": "02316"
  },
  {
    "subject": "we",
    "predicate": "suggest",
    "object": "to the user a ranked list of the semantic models for the new source",
    "sentence": "Then, we compute the top k candidate semantic models and suggest to the user a ranked list of the semantic models for the new source.",
    "id": "02316"
  },
  {
    "subject": "The approach",
    "predicate": "takes into account",
    "object": "user corrections",
    "sentence": "The approach takes into account user corrections to learn more accurate semantic models on future data sources.",
    "id": "02316"
  },
  {
    "subject": "The approach",
    "predicate": "learn",
    "object": "more accurate semantic models",
    "sentence": "The approach takes into account user corrections to learn more accurate semantic models on future data sources.",
    "id": "02316"
  },
  {
    "subject": "more accurate semantic models",
    "predicate": "on",
    "object": "future data sources",
    "sentence": "The approach takes into account user corrections to learn more accurate semantic models on future data sources.",
    "id": "02316"
  },
  {
    "subject": "our method",
    "predicate": "generates",
    "object": "expressive semantic models for data sources and services",
    "sentence": "Our evaluation shows that our method generates expressive semantic models for data sources and services with minimal user input.",
    "id": "02316"
  },
  {
    "subject": "our method",
    "predicate": "requires",
    "object": "minimal user input",
    "sentence": "Our evaluation shows that our method generates expressive semantic models for data sources and services with minimal user input.",
    "id": "02316"
  },
  {
    "subject": "These precise models",
    "predicate": "make possible",
    "object": "automatically integrate the data across sources",
    "sentence": "These precise models make it possible to automatically integrate the data across sources and provide rich support for source discovery and service composition.",
    "id": "02316"
  },
  {
    "subject": "These precise models",
    "predicate": "provide",
    "object": "rich support for source discovery and service composition",
    "sentence": "These precise models make it possible to automatically integrate the data across sources and provide rich support for source discovery and service composition.",
    "id": "02316"
  },
  {
    "subject": "They",
    "predicate": "make it possible to",
    "object": "automatically publish semantic data into knowledge graphs",
    "sentence": "They also make it possible to automatically publish semantic data into knowledge graphs.",
    "id": "02316"
  },
  {
    "subject": "Information technology",
    "predicate": "has been contributing to",
    "object": "various areas of knowledge",
    "sentence": " Information technology has been contributing to various areas of knowledge; in particular, the field of education stands out.",
    "id": "02317"
  },
  {
    "subject": "the field of education",
    "predicate": "stands out",
    "object": "in particular",
    "sentence": " Information technology has been contributing to various areas of knowledge; in particular, the field of education stands out.",
    "id": "02317"
  },
  {
    "subject": "literature",
    "predicate": "contains",
    "object": "important efforts",
    "sentence": "In what concerns the teaching of computer programming, literature contains important efforts that aim to assist in the learning process.",
    "id": "02317"
  },
  {
    "subject": "important efforts",
    "predicate": "aim to assist",
    "object": "the learning process",
    "sentence": "In what concerns the teaching of computer programming, literature contains important efforts that aim to assist in the learning process.",
    "id": "02317"
  },
  {
    "subject": "Teaching algorithms and programming concepts",
    "predicate": "has been",
    "object": "a great challenge for universities",
    "sentence": "Teaching algorithms and programming concepts for first year students has always been a great challenge for universities, new Computer Science students usually have difficulties in understanding and abstracting the problem logics.",
    "id": "02317"
  },
  {
    "subject": "new Computer Science students",
    "predicate": "have",
    "object": "difficulties in understanding and abstracting the problem logics",
    "sentence": "Teaching algorithms and programming concepts for first year students has always been a great challenge for universities, new Computer Science students usually have difficulties in understanding and abstracting the problem logics.",
    "id": "02317"
  },
  {
    "subject": "An alternative",
    "predicate": "has contributed to",
    "object": "the teaching-learning process",
    "sentence": "An alternative that has contributed to the teaching-learning process is the use of Learning Objects (LO), which contribute towards mediating and enhancing the teaching-learning process.",
    "id": "02317"
  },
  {
    "subject": "the use of Learning Objects (LO)",
    "predicate": "contribute towards",
    "object": "mediating and enhancing the teaching-learning process",
    "sentence": "An alternative that has contributed to the teaching-learning process is the use of Learning Objects (LO), which contribute towards mediating and enhancing the teaching-learning process.",
    "id": "02317"
  },
  {
    "subject": "One of the great difficulties of learning during the initial semesters of Engineering and Computer Science courses",
    "predicate": "is related to",
    "object": "the contents of computer programming",
    "sentence": "One of the great difficulties of learning during the initial semesters of Engineering and Computer Science courses is related to the contents of computer programming, which increases the students' failure level and also the dropout rate of such courses.",
    "id": "02317"
  },
  {
    "subject": "the contents of computer programming",
    "predicate": "increases",
    "object": "the students' failure level",
    "sentence": "One of the great difficulties of learning during the initial semesters of Engineering and Computer Science courses is related to the contents of computer programming, which increases the students' failure level and also the dropout rate of such courses.",
    "id": "02317"
  },
  {
    "subject": "the contents of computer programming",
    "predicate": "increases",
    "object": "the dropout rate of such courses",
    "sentence": "One of the great difficulties of learning during the initial semesters of Engineering and Computer Science courses is related to the contents of computer programming, which increases the students' failure level and also the dropout rate of such courses.",
    "id": "02317"
  },
  {
    "subject": "we",
    "predicate": "have developed",
    "object": "a project to create various learning objects",
    "sentence": "In order to decrease those rates, we have developed a project to create various learning objects to help teach concepts that are considered difficult to understand by students of Science courses, and the results were very positive.",
    "id": "02317"
  },
  {
    "subject": "learning objects",
    "predicate": "help teach",
    "object": "concepts that are considered difficult to understand by students of Science courses",
    "sentence": "In order to decrease those rates, we have developed a project to create various learning objects to help teach concepts that are considered difficult to understand by students of Science courses, and the results were very positive.",
    "id": "02317"
  },
  {
    "subject": "the results",
    "predicate": "were",
    "object": "very positive",
    "sentence": "In order to decrease those rates, we have developed a project to create various learning objects to help teach concepts that are considered difficult to understand by students of Science courses, and the results were very positive.",
    "id": "02317"
  },
  {
    "subject": "This paper",
    "predicate": "presents",
    "object": "the qualitative and quantitative results of the experiment",
    "sentence": "This paper presents the qualitative and quantitative results of the experiment we conducted with the development and application of learning objects to help teaching students of Computer Science.",
    "id": "02317"
  },
  {
    "subject": "we",
    "predicate": "conducted",
    "object": "the experiment with the development and application of learning objects",
    "sentence": "This paper presents the qualitative and quantitative results of the experiment we conducted with the development and application of learning objects to help teaching students of Computer Science.",
    "id": "02317"
  },
  {
    "subject": "learning objects",
    "predicate": "help",
    "object": "teaching students of Computer Science",
    "sentence": "This paper presents the qualitative and quantitative results of the experiment we conducted with the development and application of learning objects to help teaching students of Computer Science.",
    "id": "02317"
  },
  {
    "subject": "The project",
    "predicate": "was conducted in",
    "object": "2013 and 2014",
    "sentence": "The project was conducted in 2013 and 2014 and outcome data showed that the use of learning objects contributes significantly to the teaching-learning process.",
    "id": "02317"
  },
  {
    "subject": "The project",
    "predicate": "showed",
    "object": "that the use of learning objects contributes significantly to the teaching-learning process",
    "sentence": "The project was conducted in 2013 and 2014 and outcome data showed that the use of learning objects contributes significantly to the teaching-learning process.",
    "id": "02317"
  }
]